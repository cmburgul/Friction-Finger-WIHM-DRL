{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines[mpi]==2.10.0 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (2.10.0)\n",
      "Requirement already satisfied: joblib in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (0.14.1)\n",
      "Requirement already satisfied: pandas in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (1.0.1)\n",
      "Requirement already satisfied: matplotlib in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (3.1.1)\n",
      "Requirement already satisfied: scipy in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (1.3.2)\n",
      "Requirement already satisfied: opencv-python in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (4.1.1.26)\n",
      "Requirement already satisfied: numpy in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (1.17.3)\n",
      "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (0.15.4)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (1.2.2)\n",
      "Requirement already satisfied: mpi4py; extra == \"mpi\" in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from pandas->stable-baselines[mpi]==2.10.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from pandas->stable-baselines[mpi]==2.10.0) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.3)\n",
      "Requirement already satisfied: six in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.12.0)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.3.2)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.0.0)\n",
      "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.6)\n",
      "Requirement already satisfied: setuptools in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]==2.10.0) (41.6.0.post20191030)\n",
      "Requirement already satisfied: future in /home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.18.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cmb/anaconda3/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines[mpi]==2.10.0\n",
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.deepq.policies import FeedForwardPolicy\n",
    "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines.common.noise import AdaptiveParamNoiseSpec, NormalActionNoise\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 2\tAverage Score: 0.00"
     ]
    }
   ],
   "source": [
    "from ff_env_callback import FFEnv\n",
    "\n",
    "# Instantiate the env\n",
    "env_test = FFEnv()\n",
    "env = FFEnv()\n",
    "\n",
    "# Check the env\n",
    "check_env(env_test, warn=True)\n",
    "\n",
    "# Wrap it\n",
    "env = Monitor(env, filename=None, allow_early_resets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom MLP policy of two layers of size 32 each\n",
    "class CustomPolicy(FeedForwardPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs,\n",
    "                                           layers=[64, 64],\n",
    "                                           layer_norm=True,\n",
    "                                           feature_extraction=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Custom MLP Policy \n",
    "policy_kwargs = dict(net_arch=[256, 256])\n",
    "\n",
    "# Define the model\n",
    "#model = DQN('MlpPolicy', env, learning_rate=1e-3, prioritized_replay=True, verbose=1)\n",
    "model = PPO2('MlpPolicy', env, n_steps = 256, policy_kwargs=policy_kwargs, verbose=1)\n",
    "\n",
    "# model = PPO2(CustomPolicy, env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mean_reward = -np.inf\n",
    "n_steps = 0\n",
    "\n",
    "num_episodes = 500\n",
    "\n",
    "def callback(_locals, _globals):\n",
    "    \"\"\"\n",
    "    Callback is called at each step (timestep) for DQN\n",
    "    :param_locals: (dict)\n",
    "    :param_globals: (dict)\n",
    "    \"\"\"\n",
    "    global n_steps, best_mean_reward\n",
    "    \n",
    "    \n",
    "#     if (env.time_step_i +1) % 1000 == 0:\n",
    "#         # Evaluate policy training performance\n",
    "#         x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "#         if len(x) > 0:\n",
    "#             mean_reward = np.mean(y[-100:])\n",
    "#             print(x[-1], 'timesteps')\n",
    "#             print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n",
    "            \n",
    "#             # Next best model, you could save the agent here\n",
    "#             if mean_reward > best_mean_reward:\n",
    "#                 best_mean_reward = mean_reward\n",
    "#                 # Example for saving best model\n",
    "#                 print(\"Saving new best model\")\n",
    "#                 _locals['self'].save(log_dir + 'best_model.pkl')\n",
    "    \n",
    "    if (env.episode) > num_episodes:\n",
    "        return False\n",
    "    \n",
    "    # Returning false will stop training early\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2\tAverage Score: 0.00--------------------------------------\n",
      "| approxkl           | 0.0010379286  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0255        |\n",
      "| fps                | 64            |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 1.6083173     |\n",
      "| policy_loss        | -0.0025372158 |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 5.79e-05      |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 32.66915      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0021021722 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | 0.000271     |\n",
      "| fps                | 764          |\n",
      "| n_updates          | 2            |\n",
      "| policy_entropy     | 1.5984242    |\n",
      "| policy_loss        | -0.004635237 |\n",
      "| serial_timesteps   | 512          |\n",
      "| time_elapsed       | 3.97         |\n",
      "| total_timesteps    | 512          |\n",
      "| value_loss         | 16.389023    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0012699554   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00266        |\n",
      "| fps                | 824            |\n",
      "| n_updates          | 3              |\n",
      "| policy_entropy     | 1.5772306      |\n",
      "| policy_loss        | -0.00034174626 |\n",
      "| serial_timesteps   | 768            |\n",
      "| time_elapsed       | 4.3            |\n",
      "| total_timesteps    | 768            |\n",
      "| value_loss         | 20.89731       |\n",
      "---------------------------------------\n",
      "Episode 4\tAverage Score: -147.37--------------------------------------\n",
      "| approxkl           | 0.0027585514  |\n",
      "| clipfrac           | 0.036132812   |\n",
      "| explained_variance | 0.0572        |\n",
      "| fps                | 1036          |\n",
      "| n_updates          | 4             |\n",
      "| policy_entropy     | 1.5777194     |\n",
      "| policy_loss        | -0.0057276157 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 4.61          |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 24.047115     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0036411253  |\n",
      "| clipfrac           | 0.053710938   |\n",
      "| explained_variance | 0.0184        |\n",
      "| fps                | 1086          |\n",
      "| n_updates          | 5             |\n",
      "| policy_entropy     | 1.5690647     |\n",
      "| policy_loss        | -0.0066571264 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 4.86          |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 28.959528     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002267543   |\n",
      "| clipfrac           | 0.0107421875  |\n",
      "| explained_variance | 0.0675        |\n",
      "| fps                | 1094          |\n",
      "| n_updates          | 6             |\n",
      "| policy_entropy     | 1.5512332     |\n",
      "| policy_loss        | -0.0026933595 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 5.1           |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 18.170212     |\n",
      "--------------------------------------\n",
      "Episode 5\tAverage Score: -181.38--------------------------------------\n",
      "| approxkl           | 0.0013285886  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 1.69e+03      |\n",
      "| ep_reward_mean     | -726          |\n",
      "| explained_variance | -0.014        |\n",
      "| fps                | 991           |\n",
      "| n_updates          | 7             |\n",
      "| policy_entropy     | 1.5611961     |\n",
      "| policy_loss        | -0.0013796597 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 5.33          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 5.1488757     |\n",
      "--------------------------------------\n",
      "Episode 9\tAverage Score: -102.56--------------------------------------\n",
      "| approxkl           | 0.0003032513  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 656           |\n",
      "| ep_reward_mean     | -268          |\n",
      "| explained_variance | -0.0189       |\n",
      "| fps                | 1015          |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 1.5616127     |\n",
      "| policy_loss        | -0.0020894906 |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 5.59          |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 12.3671       |\n",
      "--------------------------------------\n",
      "Episode 10\tAverage Score: -99.13\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00079546426 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 568           |\n",
      "| ep_reward_mean     | -223          |\n",
      "| explained_variance | 0.0725        |\n",
      "| fps                | 999           |\n",
      "| n_updates          | 9             |\n",
      "| policy_entropy     | 1.5504525     |\n",
      "| policy_loss        | -0.0013399491 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 5.84          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 5.376117      |\n",
      "--------------------------------------\n",
      "Episode 11\tAverage Score: -92.95--------------------------------------\n",
      "| approxkl           | 0.0005078659  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 481           |\n",
      "| ep_reward_mean     | -186          |\n",
      "| explained_variance | 0.116         |\n",
      "| fps                | 988           |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 1.5415429     |\n",
      "| policy_loss        | -0.0007441614 |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 6.1           |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 4.0850306     |\n",
      "--------------------------------------\n",
      "Episode 13\tAverage Score: -84.55--------------------------------------\n",
      "| approxkl           | 0.00043756393 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 389           |\n",
      "| ep_reward_mean     | -145          |\n",
      "| explained_variance | 0.127         |\n",
      "| fps                | 1008          |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 1.5247275     |\n",
      "| policy_loss        | -0.002732874  |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 6.36          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 8.789373      |\n",
      "--------------------------------------\n",
      "Episode 17\tAverage Score: -68.51--------------------------------------\n",
      "| approxkl           | 0.0011756317  |\n",
      "| clipfrac           | 0.0009765625  |\n",
      "| ep_len_mean        | 327           |\n",
      "| ep_reward_mean     | -119          |\n",
      "| explained_variance | 0.176         |\n",
      "| fps                | 1070          |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 1.4983666     |\n",
      "| policy_loss        | -0.0029738068 |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 6.61          |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 8.001109      |\n",
      "--------------------------------------\n",
      "Episode 20\tAverage Score: -60.67\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006286636  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 267           |\n",
      "| ep_reward_mean     | -96.1         |\n",
      "| explained_variance | 0.211         |\n",
      "| fps                | 1008          |\n",
      "| n_updates          | 13            |\n",
      "| policy_entropy     | 1.4788724     |\n",
      "| policy_loss        | -0.0017240529 |\n",
      "| serial_timesteps   | 3328          |\n",
      "| time_elapsed       | 6.85          |\n",
      "| total_timesteps    | 3328          |\n",
      "| value_loss         | 5.7829227     |\n",
      "--------------------------------------\n",
      "Episode 23\tAverage Score: -56.04--------------------------------------\n",
      "| approxkl           | 0.0018105742  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 237           |\n",
      "| ep_reward_mean     | -82.2         |\n",
      "| explained_variance | 0.337         |\n",
      "| fps                | 1063          |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 1.475063      |\n",
      "| policy_loss        | -0.0073797875 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 7.11          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 4.8830247     |\n",
      "--------------------------------------\n",
      "Episode 26\tAverage Score: -52.30-------------------------------------\n",
      "| approxkl           | 0.005941535  |\n",
      "| clipfrac           | 0.0546875    |\n",
      "| ep_len_mean        | 212          |\n",
      "| ep_reward_mean     | -72.6        |\n",
      "| explained_variance | 0.382        |\n",
      "| fps                | 1081         |\n",
      "| n_updates          | 15           |\n",
      "| policy_entropy     | 1.4492668    |\n",
      "| policy_loss        | -0.008699007 |\n",
      "| serial_timesteps   | 3840         |\n",
      "| time_elapsed       | 7.35         |\n",
      "| total_timesteps    | 3840         |\n",
      "| value_loss         | 6.2116137    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30\tAverage Score: -47.20\n",
      "Episode 30\tAverage Score: -47.20\n",
      "Episode 31\tAverage Score: -46.17---------------------------------------\n",
      "| approxkl           | 0.0010580521   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 193            |\n",
      "| ep_reward_mean     | -66            |\n",
      "| explained_variance | 0.373          |\n",
      "| fps                | 1074           |\n",
      "| n_updates          | 16             |\n",
      "| policy_entropy     | 1.3710066      |\n",
      "| policy_loss        | -0.00089734857 |\n",
      "| serial_timesteps   | 4096           |\n",
      "| time_elapsed       | 7.59           |\n",
      "| total_timesteps    | 4096           |\n",
      "| value_loss         | 8.262725       |\n",
      "---------------------------------------\n",
      "Episode 36\tAverage Score: -42.45--------------------------------------\n",
      "| approxkl           | 0.0010280813  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 167           |\n",
      "| ep_reward_mean     | -57.1         |\n",
      "| explained_variance | 0.48          |\n",
      "| fps                | 1060          |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 1.3443272     |\n",
      "| policy_loss        | -0.0034555006 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 7.83          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 7.1584263     |\n",
      "--------------------------------------\n",
      "Episode 38\tAverage Score: -41.08-------------------------------------\n",
      "| approxkl           | 0.001591966  |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -54.3        |\n",
      "| explained_variance | 0.423        |\n",
      "| fps                | 1012         |\n",
      "| n_updates          | 18           |\n",
      "| policy_entropy     | 1.4126827    |\n",
      "| policy_loss        | 0.0011685307 |\n",
      "| serial_timesteps   | 4608         |\n",
      "| time_elapsed       | 8.07         |\n",
      "| total_timesteps    | 4608         |\n",
      "| value_loss         | 4.665619     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0031913696  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 158           |\n",
      "| ep_reward_mean     | -54.3         |\n",
      "| explained_variance | -0.0268       |\n",
      "| fps                | 1029          |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 1.521805      |\n",
      "| policy_loss        | -0.0031089876 |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 8.32          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 5.9348736     |\n",
      "--------------------------------------\n",
      "Episode 40\tAverage Score: -42.69\n",
      "Episode 40\tAverage Score: -42.69\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0022445295 |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -54.3        |\n",
      "| explained_variance | 0.171        |\n",
      "| fps                | 983          |\n",
      "| n_updates          | 20           |\n",
      "| policy_entropy     | 1.4111286    |\n",
      "| policy_loss        | -0.003227783 |\n",
      "| serial_timesteps   | 5120         |\n",
      "| time_elapsed       | 8.57         |\n",
      "| total_timesteps    | 5120         |\n",
      "| value_loss         | 8.032291     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0090178065 |\n",
      "| clipfrac           | 0.16308594   |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -54.3        |\n",
      "| explained_variance | -0.00958     |\n",
      "| fps                | 1049         |\n",
      "| n_updates          | 21           |\n",
      "| policy_entropy     | 1.3820512    |\n",
      "| policy_loss        | -0.004283946 |\n",
      "| serial_timesteps   | 5376         |\n",
      "| time_elapsed       | 8.83         |\n",
      "| total_timesteps    | 5376         |\n",
      "| value_loss         | 4.5476174    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018609234  |\n",
      "| clipfrac           | 0.044921875   |\n",
      "| ep_len_mean        | 158           |\n",
      "| ep_reward_mean     | -54.3         |\n",
      "| explained_variance | 0.00368       |\n",
      "| fps                | 1136          |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 1.3640672     |\n",
      "| policy_loss        | -0.0047891024 |\n",
      "| serial_timesteps   | 5632          |\n",
      "| time_elapsed       | 9.08          |\n",
      "| total_timesteps    | 5632          |\n",
      "| value_loss         | 4.0311985     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0008308336  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 158           |\n",
      "| ep_reward_mean     | -54.3         |\n",
      "| explained_variance | -0.0186       |\n",
      "| fps                | 1133          |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 1.3946007     |\n",
      "| policy_loss        | -0.0015273812 |\n",
      "| serial_timesteps   | 5888          |\n",
      "| time_elapsed       | 9.3           |\n",
      "| total_timesteps    | 5888          |\n",
      "| value_loss         | 3.6775124     |\n",
      "--------------------------------------\n",
      "Episode 42\tAverage Score: -46.74-------------------------------------\n",
      "| approxkl           | 0.003224464  |\n",
      "| clipfrac           | 0.046875     |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -54.3        |\n",
      "| explained_variance | 0.52         |\n",
      "| fps                | 1110         |\n",
      "| n_updates          | 24           |\n",
      "| policy_entropy     | 1.4115909    |\n",
      "| policy_loss        | -0.012299393 |\n",
      "| serial_timesteps   | 6144         |\n",
      "| time_elapsed       | 9.53         |\n",
      "| total_timesteps    | 6144         |\n",
      "| value_loss         | 9.8941765    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0054977783 |\n",
      "| clipfrac           | 0.055664062  |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -54.3        |\n",
      "| explained_variance | 0.0157       |\n",
      "| fps                | 1127         |\n",
      "| n_updates          | 25           |\n",
      "| policy_entropy     | 1.4297738    |\n",
      "| policy_loss        | -0.007931372 |\n",
      "| serial_timesteps   | 6400         |\n",
      "| time_elapsed       | 9.76         |\n",
      "| total_timesteps    | 6400         |\n",
      "| value_loss         | 3.494843     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.007214387  |\n",
      "| clipfrac           | 0.13378906   |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -54.3        |\n",
      "| explained_variance | -0.0165      |\n",
      "| fps                | 1074         |\n",
      "| n_updates          | 26           |\n",
      "| policy_entropy     | 1.3221599    |\n",
      "| policy_loss        | -0.006755796 |\n",
      "| serial_timesteps   | 6656         |\n",
      "| time_elapsed       | 9.99         |\n",
      "| total_timesteps    | 6656         |\n",
      "| value_loss         | 3.120491     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.006323669   |\n",
      "| clipfrac           | 0.057617188   |\n",
      "| ep_len_mean        | 158           |\n",
      "| ep_reward_mean     | -54.3         |\n",
      "| explained_variance | 0.0105        |\n",
      "| fps                | 1039          |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 1.2044373     |\n",
      "| policy_loss        | -0.0010888425 |\n",
      "| serial_timesteps   | 6912          |\n",
      "| time_elapsed       | 10.2          |\n",
      "| total_timesteps    | 6912          |\n",
      "| value_loss         | 2.7432072     |\n",
      "--------------------------------------\n",
      "Episode 45\tAverage Score: -50.11-------------------------------------\n",
      "| approxkl           | 0.0044641383 |\n",
      "| clipfrac           | 0.053710938  |\n",
      "| ep_len_mean        | 243          |\n",
      "| ep_reward_mean     | -76          |\n",
      "| explained_variance | -0.0218      |\n",
      "| fps                | 1068         |\n",
      "| n_updates          | 28           |\n",
      "| policy_entropy     | 1.1335166    |\n",
      "| policy_loss        | -0.00723703  |\n",
      "| serial_timesteps   | 7168         |\n",
      "| time_elapsed       | 10.5         |\n",
      "| total_timesteps    | 7168         |\n",
      "| value_loss         | 7.6037025    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0013151646  |\n",
      "| clipfrac           | 0.013671875   |\n",
      "| ep_len_mean        | 243           |\n",
      "| ep_reward_mean     | -76           |\n",
      "| explained_variance | 0.00478       |\n",
      "| fps                | 1136          |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 1.1963589     |\n",
      "| policy_loss        | -0.0008416361 |\n",
      "| serial_timesteps   | 7424          |\n",
      "| time_elapsed       | 10.7          |\n",
      "| total_timesteps    | 7424          |\n",
      "| value_loss         | 1.9419092     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0014533042  |\n",
      "| clipfrac           | 0.00390625    |\n",
      "| ep_len_mean        | 243           |\n",
      "| ep_reward_mean     | -76           |\n",
      "| explained_variance | -0.0106       |\n",
      "| fps                | 1131          |\n",
      "| n_updates          | 30            |\n",
      "| policy_entropy     | 1.1813025     |\n",
      "| policy_loss        | -0.0013759816 |\n",
      "| serial_timesteps   | 7680          |\n",
      "| time_elapsed       | 10.9          |\n",
      "| total_timesteps    | 7680          |\n",
      "| value_loss         | 1.6733637     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.009628901   |\n",
      "| clipfrac           | 0.17578125    |\n",
      "| ep_len_mean        | 243           |\n",
      "| ep_reward_mean     | -76           |\n",
      "| explained_variance | 0.00223       |\n",
      "| fps                | 1157          |\n",
      "| n_updates          | 31            |\n",
      "| policy_entropy     | 1.1527928     |\n",
      "| policy_loss        | -0.0068980795 |\n",
      "| serial_timesteps   | 7936          |\n",
      "| time_elapsed       | 11.2          |\n",
      "| total_timesteps    | 7936          |\n",
      "| value_loss         | 1.4815378     |\n",
      "--------------------------------------\n",
      "Episode 50\tAverage Score: -50.88\n",
      "Episode 51\tAverage Score: -50.13-------------------------------------\n",
      "| approxkl           | 0.0025418075 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 247          |\n",
      "| ep_reward_mean     | -75.9        |\n",
      "| explained_variance | 0.0043       |\n",
      "| fps                | 1019         |\n",
      "| n_updates          | 32           |\n",
      "| policy_entropy     | 1.0730476    |\n",
      "| policy_loss        | 0.0016779256 |\n",
      "| serial_timesteps   | 8192         |\n",
      "| time_elapsed       | 11.4         |\n",
      "| total_timesteps    | 8192         |\n",
      "| value_loss         | 21.35144     |\n",
      "-------------------------------------\n",
      "Episode 54\tAverage Score: -48.09--------------------------------------\n",
      "| approxkl           | 0.00018968835 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 230           |\n",
      "| ep_reward_mean     | -70.8         |\n",
      "| explained_variance | -0.0279       |\n",
      "| fps                | 931           |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 1.0925637     |\n",
      "| policy_loss        | -0.0011476224 |\n",
      "| serial_timesteps   | 8448          |\n",
      "| time_elapsed       | 11.6          |\n",
      "| total_timesteps    | 8448          |\n",
      "| value_loss         | 11.130507     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009117306  |\n",
      "| clipfrac           | 0.21582031   |\n",
      "| ep_len_mean        | 230          |\n",
      "| ep_reward_mean     | -70.8        |\n",
      "| explained_variance | -5.71e-05    |\n",
      "| fps                | 1147         |\n",
      "| n_updates          | 34           |\n",
      "| policy_entropy     | 1.0703989    |\n",
      "| policy_loss        | -0.006384914 |\n",
      "| serial_timesteps   | 8704         |\n",
      "| time_elapsed       | 11.9         |\n",
      "| total_timesteps    | 8704         |\n",
      "| value_loss         | 1.0741439    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.005724462 |\n",
      "| clipfrac           | 0.10644531  |\n",
      "| ep_len_mean        | 230         |\n",
      "| ep_reward_mean     | -70.8       |\n",
      "| explained_variance | 0.00139     |\n",
      "| fps                | 1168        |\n",
      "| n_updates          | 35          |\n",
      "| policy_entropy     | 1.0063494   |\n",
      "| policy_loss        | -0.01060142 |\n",
      "| serial_timesteps   | 8960        |\n",
      "| time_elapsed       | 12.1        |\n",
      "| total_timesteps    | 8960        |\n",
      "| value_loss         | 0.90738416  |\n",
      "------------------------------------\n",
      "Episode 56\tAverage Score: -49.66--------------------------------------\n",
      "| approxkl           | 0.005198758   |\n",
      "| clipfrac           | 0.016601562   |\n",
      "| ep_len_mean        | 230           |\n",
      "| ep_reward_mean     | -70.8         |\n",
      "| explained_variance | 0.137         |\n",
      "| fps                | 1113          |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.9749446     |\n",
      "| policy_loss        | -0.0008693028 |\n",
      "| serial_timesteps   | 9216          |\n",
      "| time_elapsed       | 12.4          |\n",
      "| total_timesteps    | 9216          |\n",
      "| value_loss         | 1.7204665     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.002709473  |\n",
      "| clipfrac           | 0.044921875  |\n",
      "| ep_len_mean        | 230          |\n",
      "| ep_reward_mean     | -70.8        |\n",
      "| explained_variance | 0.00102      |\n",
      "| fps                | 1143         |\n",
      "| n_updates          | 37           |\n",
      "| policy_entropy     | 0.928717     |\n",
      "| policy_loss        | -0.003562042 |\n",
      "| serial_timesteps   | 9472         |\n",
      "| time_elapsed       | 12.6         |\n",
      "| total_timesteps    | 9472         |\n",
      "| value_loss         | 0.77953416   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0042827707  |\n",
      "| clipfrac           | 0.052734375   |\n",
      "| ep_len_mean        | 230           |\n",
      "| ep_reward_mean     | -70.8         |\n",
      "| explained_variance | 0.000446      |\n",
      "| fps                | 1152          |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.9675855     |\n",
      "| policy_loss        | -0.0019064366 |\n",
      "| serial_timesteps   | 9728          |\n",
      "| time_elapsed       | 12.8          |\n",
      "| total_timesteps    | 9728          |\n",
      "| value_loss         | 0.6187998     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004465949   |\n",
      "| clipfrac           | 0.059570312   |\n",
      "| ep_len_mean        | 230           |\n",
      "| ep_reward_mean     | -70.8         |\n",
      "| explained_variance | -0.000648     |\n",
      "| fps                | 1124          |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 1.0744374     |\n",
      "| policy_loss        | -0.0048776213 |\n",
      "| serial_timesteps   | 9984          |\n",
      "| time_elapsed       | 13            |\n",
      "| total_timesteps    | 9984          |\n",
      "| value_loss         | 0.49824002    |\n",
      "--------------------------------------\n",
      "Episode 58\tAverage Score: -52.37--------------------------------------\n",
      "| approxkl           | 0.0020459318  |\n",
      "| clipfrac           | 0.021484375   |\n",
      "| ep_len_mean        | 230           |\n",
      "| ep_reward_mean     | -70.8         |\n",
      "| explained_variance | 0.262         |\n",
      "| fps                | 1086          |\n",
      "| n_updates          | 40            |\n",
      "| policy_entropy     | 1.0832727     |\n",
      "| policy_loss        | -0.0021650135 |\n",
      "| serial_timesteps   | 10240         |\n",
      "| time_elapsed       | 13.3          |\n",
      "| total_timesteps    | 10240         |\n",
      "| value_loss         | 1.3934124     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0047826036 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 230          |\n",
      "| ep_reward_mean     | -70.8        |\n",
      "| explained_variance | 0.00258      |\n",
      "| fps                | 1132         |\n",
      "| n_updates          | 41           |\n",
      "| policy_entropy     | 1.2337948    |\n",
      "| policy_loss        | 0.0025988624 |\n",
      "| serial_timesteps   | 10496        |\n",
      "| time_elapsed       | 13.5         |\n",
      "| total_timesteps    | 10496        |\n",
      "| value_loss         | 0.2094164    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004360361   |\n",
      "| clipfrac           | 0.052734375   |\n",
      "| ep_len_mean        | 230           |\n",
      "| ep_reward_mean     | -70.8         |\n",
      "| explained_variance | -0.000602     |\n",
      "| fps                | 1109          |\n",
      "| n_updates          | 42            |\n",
      "| policy_entropy     | 1.2054636     |\n",
      "| policy_loss        | -0.0051822555 |\n",
      "| serial_timesteps   | 10752         |\n",
      "| time_elapsed       | 13.7          |\n",
      "| total_timesteps    | 10752         |\n",
      "| value_loss         | 0.14290713    |\n",
      "--------------------------------------\n",
      "Episode 60\tAverage Score: -54.81\n",
      "Episode 60\tAverage Score: -54.81\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0073677427 |\n",
      "| clipfrac           | 0.115234375  |\n",
      "| ep_len_mean        | 230          |\n",
      "| ep_reward_mean     | -70.8        |\n",
      "| explained_variance | 0.156        |\n",
      "| fps                | 1140         |\n",
      "| n_updates          | 43           |\n",
      "| policy_entropy     | 1.1917775    |\n",
      "| policy_loss        | -0.009097336 |\n",
      "| serial_timesteps   | 11008        |\n",
      "| time_elapsed       | 14           |\n",
      "| total_timesteps    | 11008        |\n",
      "| value_loss         | 0.43891242   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 65\tAverage Score: -51.80------------------------------------\n",
      "| approxkl           | 0.012894124 |\n",
      "| clipfrac           | 0.19628906  |\n",
      "| ep_len_mean        | 275         |\n",
      "| ep_reward_mean     | -80.9       |\n",
      "| explained_variance | 0.0728      |\n",
      "| fps                | 1048        |\n",
      "| n_updates          | 44          |\n",
      "| policy_entropy     | 1.3778068   |\n",
      "| policy_loss        | 0.016222544 |\n",
      "| serial_timesteps   | 11264       |\n",
      "| time_elapsed       | 14.2        |\n",
      "| total_timesteps    | 11264       |\n",
      "| value_loss         | 48.32618    |\n",
      "------------------------------------\n",
      "Episode 70\tAverage Score: -49.23\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0019439666   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 250            |\n",
      "| ep_reward_mean     | -73.8          |\n",
      "| explained_variance | 0.0721         |\n",
      "| fps                | 1037           |\n",
      "| n_updates          | 45             |\n",
      "| policy_entropy     | 1.351166       |\n",
      "| policy_loss        | -0.00013871468 |\n",
      "| serial_timesteps   | 11520          |\n",
      "| time_elapsed       | 14.4           |\n",
      "| total_timesteps    | 11520          |\n",
      "| value_loss         | 47.0341        |\n",
      "---------------------------------------\n",
      "Episode 74\tAverage Score: -47.41--------------------------------------\n",
      "| approxkl           | 0.00041561795 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 234           |\n",
      "| ep_reward_mean     | -69.2         |\n",
      "| explained_variance | 0.0714        |\n",
      "| fps                | 1049          |\n",
      "| n_updates          | 46            |\n",
      "| policy_entropy     | 1.3311944     |\n",
      "| policy_loss        | -0.0020926052 |\n",
      "| serial_timesteps   | 11776         |\n",
      "| time_elapsed       | 14.7          |\n",
      "| total_timesteps    | 11776         |\n",
      "| value_loss         | 37.66901      |\n",
      "--------------------------------------\n",
      "Episode 81\tAverage Score: -44.45--------------------------------------\n",
      "| approxkl           | 0.0013212285  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 218           |\n",
      "| ep_reward_mean     | -64.6         |\n",
      "| explained_variance | 0.0815        |\n",
      "| fps                | 1075          |\n",
      "| n_updates          | 47            |\n",
      "| policy_entropy     | 1.376975      |\n",
      "| policy_loss        | 0.00056767487 |\n",
      "| serial_timesteps   | 12032         |\n",
      "| time_elapsed       | 14.9          |\n",
      "| total_timesteps    | 12032         |\n",
      "| value_loss         | 42.09726      |\n",
      "--------------------------------------\n",
      "Episode 85\tAverage Score: -43.39--------------------------------------\n",
      "| approxkl           | 0.00027657108 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 208           |\n",
      "| ep_reward_mean     | -61.8         |\n",
      "| explained_variance | 0.0984        |\n",
      "| fps                | 1068          |\n",
      "| n_updates          | 48            |\n",
      "| policy_entropy     | 1.3822503     |\n",
      "| policy_loss        | -0.0015818048 |\n",
      "| serial_timesteps   | 12288         |\n",
      "| time_elapsed       | 15.2          |\n",
      "| total_timesteps    | 12288         |\n",
      "| value_loss         | 36.61979      |\n",
      "--------------------------------------\n",
      "Episode 89\tAverage Score: -42.38--------------------------------------\n",
      "| approxkl           | 0.00021370695 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 199           |\n",
      "| ep_reward_mean     | -59.2         |\n",
      "| explained_variance | 0.113         |\n",
      "| fps                | 1027          |\n",
      "| n_updates          | 49            |\n",
      "| policy_entropy     | 1.3826202     |\n",
      "| policy_loss        | 0.000647671   |\n",
      "| serial_timesteps   | 12544         |\n",
      "| time_elapsed       | 15.4          |\n",
      "| total_timesteps    | 12544         |\n",
      "| value_loss         | 35.136723     |\n",
      "--------------------------------------\n",
      "Episode 90\tAverage Score: -42.09\n",
      "Episode 93\tAverage Score: -41.31--------------------------------------\n",
      "| approxkl           | 0.00028897618 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 191           |\n",
      "| ep_reward_mean     | -56.7         |\n",
      "| explained_variance | 0.142         |\n",
      "| fps                | 996           |\n",
      "| n_updates          | 50            |\n",
      "| policy_entropy     | 1.3754525     |\n",
      "| policy_loss        | 0.00018770644 |\n",
      "| serial_timesteps   | 12800         |\n",
      "| time_elapsed       | 15.6          |\n",
      "| total_timesteps    | 12800         |\n",
      "| value_loss         | 34.71624      |\n",
      "--------------------------------------\n",
      "Episode 99\tAverage Score: -39.60-------------------------------------\n",
      "| approxkl           | 0.0005723678 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 183          |\n",
      "| ep_reward_mean     | -54.6        |\n",
      "| explained_variance | 0.148        |\n",
      "| fps                | 989          |\n",
      "| n_updates          | 51           |\n",
      "| policy_entropy     | 1.3544935    |\n",
      "| policy_loss        | -0.00160129  |\n",
      "| serial_timesteps   | 13056        |\n",
      "| time_elapsed       | 15.9         |\n",
      "| total_timesteps    | 13056        |\n",
      "| value_loss         | 33.183105    |\n",
      "-------------------------------------\n",
      "Episode 100\tAverage Score: -39.42\n",
      "Episode 104\tAverage Score: -35.42-------------------------------------\n",
      "| approxkl           | 0.0014005061 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 175          |\n",
      "| ep_reward_mean     | -52.4        |\n",
      "| explained_variance | 0.183        |\n",
      "| fps                | 1002         |\n",
      "| n_updates          | 52           |\n",
      "| policy_entropy     | 1.325379     |\n",
      "| policy_loss        | -0.004749256 |\n",
      "| serial_timesteps   | 13312        |\n",
      "| time_elapsed       | 16.2         |\n",
      "| total_timesteps    | 13312        |\n",
      "| value_loss         | 35.958714    |\n",
      "-------------------------------------\n",
      "Episode 109\tAverage Score: -32.39--------------------------------------\n",
      "| approxkl           | 0.0025738582  |\n",
      "| clipfrac           | 0.017578125   |\n",
      "| ep_len_mean        | 167           |\n",
      "| ep_reward_mean     | -50.1         |\n",
      "| explained_variance | 0.237         |\n",
      "| fps                | 1055          |\n",
      "| n_updates          | 53            |\n",
      "| policy_entropy     | 1.2682949     |\n",
      "| policy_loss        | -0.0034029798 |\n",
      "| serial_timesteps   | 13568         |\n",
      "| time_elapsed       | 16.4          |\n",
      "| total_timesteps    | 13568         |\n",
      "| value_loss         | 39.432224     |\n",
      "--------------------------------------\n",
      "Episode 110\tAverage Score: -31.86\n",
      "Episode 114\tAverage Score: -30.86-------------------------------------\n",
      "| approxkl           | 0.0055200476 |\n",
      "| clipfrac           | 0.032226562  |\n",
      "| ep_len_mean        | 160          |\n",
      "| ep_reward_mean     | -48.1        |\n",
      "| explained_variance | 0.243        |\n",
      "| fps                | 1043         |\n",
      "| n_updates          | 54           |\n",
      "| policy_entropy     | 1.1800766    |\n",
      "| policy_loss        | -0.006015415 |\n",
      "| serial_timesteps   | 13824        |\n",
      "| time_elapsed       | 16.7         |\n",
      "| total_timesteps    | 13824        |\n",
      "| value_loss         | 36.47027     |\n",
      "-------------------------------------\n",
      "Episode 120\tAverage Score: -30.65\n",
      "Episode 120\tAverage Score: -30.65\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0015319678 |\n",
      "| clipfrac           | 0.005859375  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | 0.226        |\n",
      "| fps                | 1056         |\n",
      "| n_updates          | 55           |\n",
      "| policy_entropy     | 1.1355023    |\n",
      "| policy_loss        | -0.004337476 |\n",
      "| serial_timesteps   | 14080        |\n",
      "| time_elapsed       | 16.9         |\n",
      "| total_timesteps    | 14080        |\n",
      "| value_loss         | 28.544254    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.003156039  |\n",
      "| clipfrac           | 0.048828125  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | 0.0022       |\n",
      "| fps                | 1160         |\n",
      "| n_updates          | 56           |\n",
      "| policy_entropy     | 1.2109069    |\n",
      "| policy_loss        | -0.004404701 |\n",
      "| serial_timesteps   | 14336        |\n",
      "| time_elapsed       | 17.2         |\n",
      "| total_timesteps    | 14336        |\n",
      "| value_loss         | 0.6397113    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.013075473  |\n",
      "| clipfrac           | 0.18652344   |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | 0.00158      |\n",
      "| fps                | 1152         |\n",
      "| n_updates          | 57           |\n",
      "| policy_entropy     | 1.1166042    |\n",
      "| policy_loss        | -0.008094934 |\n",
      "| serial_timesteps   | 14592        |\n",
      "| time_elapsed       | 17.4         |\n",
      "| total_timesteps    | 14592        |\n",
      "| value_loss         | 0.44225174   |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.004007965  |\n",
      "| clipfrac           | 0.115234375  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | 0.000735     |\n",
      "| fps                | 1116         |\n",
      "| n_updates          | 58           |\n",
      "| policy_entropy     | 1.0481654    |\n",
      "| policy_loss        | -0.001981895 |\n",
      "| serial_timesteps   | 14848        |\n",
      "| time_elapsed       | 17.6         |\n",
      "| total_timesteps    | 14848        |\n",
      "| value_loss         | 0.35286027   |\n",
      "-------------------------------------\n",
      "Episode 122\tAverage Score: -32.53--------------------------------------\n",
      "| approxkl           | 0.0040158434  |\n",
      "| clipfrac           | 0.02734375    |\n",
      "| ep_len_mean        | 155           |\n",
      "| ep_reward_mean     | -46.7         |\n",
      "| explained_variance | 0.27          |\n",
      "| fps                | 1136          |\n",
      "| n_updates          | 59            |\n",
      "| policy_entropy     | 0.9919171     |\n",
      "| policy_loss        | -0.0024239975 |\n",
      "| serial_timesteps   | 15104         |\n",
      "| time_elapsed       | 17.8          |\n",
      "| total_timesteps    | 15104         |\n",
      "| value_loss         | 1.8764942     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.009079926  |\n",
      "| clipfrac           | 0.12402344   |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | 0.000974     |\n",
      "| fps                | 1170         |\n",
      "| n_updates          | 60           |\n",
      "| policy_entropy     | 0.9834371    |\n",
      "| policy_loss        | -0.009472942 |\n",
      "| serial_timesteps   | 15360        |\n",
      "| time_elapsed       | 18.1         |\n",
      "| total_timesteps    | 15360        |\n",
      "| value_loss         | 0.22376701   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0014502074 |\n",
      "| clipfrac           | 0.005859375  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | -0.00506     |\n",
      "| fps                | 1140         |\n",
      "| n_updates          | 61           |\n",
      "| policy_entropy     | 0.8643739    |\n",
      "| policy_loss        | 0.0015239153 |\n",
      "| serial_timesteps   | 15616        |\n",
      "| time_elapsed       | 18.3         |\n",
      "| total_timesteps    | 15616        |\n",
      "| value_loss         | 0.14993392   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.004458889    |\n",
      "| clipfrac           | 0.033203125    |\n",
      "| ep_len_mean        | 155            |\n",
      "| ep_reward_mean     | -46.7          |\n",
      "| explained_variance | 0.000728       |\n",
      "| fps                | 1142           |\n",
      "| n_updates          | 62             |\n",
      "| policy_entropy     | 0.99336624     |\n",
      "| policy_loss        | -0.00083860324 |\n",
      "| serial_timesteps   | 15872          |\n",
      "| time_elapsed       | 18.5           |\n",
      "| total_timesteps    | 15872          |\n",
      "| value_loss         | 0.10311469     |\n",
      "---------------------------------------\n",
      "Episode 124\tAverage Score: -34.65-------------------------------------\n",
      "| approxkl           | 0.0031018502 |\n",
      "| clipfrac           | 0.037109375  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | 0.23         |\n",
      "| fps                | 1108         |\n",
      "| n_updates          | 63           |\n",
      "| policy_entropy     | 0.7955725    |\n",
      "| policy_loss        | 0.0032891084 |\n",
      "| serial_timesteps   | 16128        |\n",
      "| time_elapsed       | 18.7         |\n",
      "| total_timesteps    | 16128        |\n",
      "| value_loss         | 1.2862353    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0036173176 |\n",
      "| clipfrac           | 0.044921875  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | -0.00199     |\n",
      "| fps                | 1110         |\n",
      "| n_updates          | 64           |\n",
      "| policy_entropy     | 0.9369645    |\n",
      "| policy_loss        | -0.005659668 |\n",
      "| serial_timesteps   | 16384        |\n",
      "| time_elapsed       | 19           |\n",
      "| total_timesteps    | 16384        |\n",
      "| value_loss         | 0.105593726  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0041905716 |\n",
      "| clipfrac           | 0.05078125   |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | -0.00926     |\n",
      "| fps                | 1108         |\n",
      "| n_updates          | 65           |\n",
      "| policy_entropy     | 0.91609263   |\n",
      "| policy_loss        | -0.00769425  |\n",
      "| serial_timesteps   | 16640        |\n",
      "| time_elapsed       | 19.2         |\n",
      "| total_timesteps    | 16640        |\n",
      "| value_loss         | 0.07578998   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0018135109 |\n",
      "| clipfrac           | 0.029296875  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | -0.00207     |\n",
      "| fps                | 1106         |\n",
      "| n_updates          | 66           |\n",
      "| policy_entropy     | 0.81774545   |\n",
      "| policy_loss        | -0.003301692 |\n",
      "| serial_timesteps   | 16896        |\n",
      "| time_elapsed       | 19.4         |\n",
      "| total_timesteps    | 16896        |\n",
      "| value_loss         | 0.041628808  |\n",
      "-------------------------------------\n",
      "Episode 126\tAverage Score: -36.64--------------------------------------\n",
      "| approxkl           | 0.0026311977  |\n",
      "| clipfrac           | 0.05859375    |\n",
      "| ep_len_mean        | 155           |\n",
      "| ep_reward_mean     | -46.7         |\n",
      "| explained_variance | 0.313         |\n",
      "| fps                | 931           |\n",
      "| n_updates          | 67            |\n",
      "| policy_entropy     | 0.85217184    |\n",
      "| policy_loss        | -0.0035389278 |\n",
      "| serial_timesteps   | 17152         |\n",
      "| time_elapsed       | 19.6          |\n",
      "| total_timesteps    | 17152         |\n",
      "| value_loss         | 1.8916644     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0017610299  |\n",
      "| clipfrac           | 0.021484375   |\n",
      "| ep_len_mean        | 155           |\n",
      "| ep_reward_mean     | -46.7         |\n",
      "| explained_variance | -0.0068       |\n",
      "| fps                | 1089          |\n",
      "| n_updates          | 68            |\n",
      "| policy_entropy     | 0.99145347    |\n",
      "| policy_loss        | -0.0010027856 |\n",
      "| serial_timesteps   | 17408         |\n",
      "| time_elapsed       | 19.9          |\n",
      "| total_timesteps    | 17408         |\n",
      "| value_loss         | 0.01200699    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004835215   |\n",
      "| clipfrac           | 0.048828125   |\n",
      "| ep_len_mean        | 155           |\n",
      "| ep_reward_mean     | -46.7         |\n",
      "| explained_variance | -0.00764      |\n",
      "| fps                | 1136          |\n",
      "| n_updates          | 69            |\n",
      "| policy_entropy     | 0.98149765    |\n",
      "| policy_loss        | -0.0055566235 |\n",
      "| serial_timesteps   | 17664         |\n",
      "| time_elapsed       | 20.2          |\n",
      "| total_timesteps    | 17664         |\n",
      "| value_loss         | 0.0081598675  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.012386457  |\n",
      "| clipfrac           | 0.099609375  |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | -0.0452      |\n",
      "| fps                | 1176         |\n",
      "| n_updates          | 70           |\n",
      "| policy_entropy     | 1.1065333    |\n",
      "| policy_loss        | -0.013486472 |\n",
      "| serial_timesteps   | 17920        |\n",
      "| time_elapsed       | 20.4         |\n",
      "| total_timesteps    | 17920        |\n",
      "| value_loss         | 0.004596186  |\n",
      "-------------------------------------\n",
      "Episode 128\tAverage Score: -38.79--------------------------------------\n",
      "| approxkl           | 0.0016553751  |\n",
      "| clipfrac           | 0.013671875   |\n",
      "| ep_len_mean        | 155           |\n",
      "| ep_reward_mean     | -46.7         |\n",
      "| explained_variance | 0.166         |\n",
      "| fps                | 1085          |\n",
      "| n_updates          | 71            |\n",
      "| policy_entropy     | 1.0924592     |\n",
      "| policy_loss        | -0.0007202637 |\n",
      "| serial_timesteps   | 18176         |\n",
      "| time_elapsed       | 20.6          |\n",
      "| total_timesteps    | 18176         |\n",
      "| value_loss         | 1.3961323     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.019438185  |\n",
      "| clipfrac           | 0.34960938   |\n",
      "| ep_len_mean        | 155          |\n",
      "| ep_reward_mean     | -46.7        |\n",
      "| explained_variance | -0.0588      |\n",
      "| fps                | 1117         |\n",
      "| n_updates          | 72           |\n",
      "| policy_entropy     | 1.1933931    |\n",
      "| policy_loss        | -0.027842151 |\n",
      "| serial_timesteps   | 18432        |\n",
      "| time_elapsed       | 20.8         |\n",
      "| total_timesteps    | 18432        |\n",
      "| value_loss         | 0.0057861675 |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.025021533 |\n",
      "| clipfrac           | 0.44335938  |\n",
      "| ep_len_mean        | 155         |\n",
      "| ep_reward_mean     | -46.7       |\n",
      "| explained_variance | -0.0553     |\n",
      "| fps                | 1139        |\n",
      "| n_updates          | 73          |\n",
      "| policy_entropy     | 1.2323868   |\n",
      "| policy_loss        | -0.03025452 |\n",
      "| serial_timesteps   | 18688       |\n",
      "| time_elapsed       | 21.1        |\n",
      "| total_timesteps    | 18688       |\n",
      "| value_loss         | 0.007053081 |\n",
      "------------------------------------\n",
      "Episode 129\tAverage Score: -40.44-------------------------------------\n",
      "| approxkl           | 0.0034545562 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 206          |\n",
      "| ep_reward_mean     | -59.5        |\n",
      "| explained_variance | 0.143        |\n",
      "| fps                | 1107         |\n",
      "| n_updates          | 74           |\n",
      "| policy_entropy     | 1.2306519    |\n",
      "| policy_loss        | 0.010760107  |\n",
      "| serial_timesteps   | 18944        |\n",
      "| time_elapsed       | 21.3         |\n",
      "| total_timesteps    | 18944        |\n",
      "| value_loss         | 15.562243    |\n",
      "-------------------------------------\n",
      "Episode 131\tAverage Score: -40.86-------------------------------------\n",
      "| approxkl           | 0.0014617094 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 206          |\n",
      "| ep_reward_mean     | -59.5        |\n",
      "| explained_variance | 0.264        |\n",
      "| fps                | 1087         |\n",
      "| n_updates          | 75           |\n",
      "| policy_entropy     | 1.2252198    |\n",
      "| policy_loss        | 0.0035265363 |\n",
      "| serial_timesteps   | 19200        |\n",
      "| time_elapsed       | 21.5         |\n",
      "| total_timesteps    | 19200        |\n",
      "| value_loss         | 10.681672    |\n",
      "-------------------------------------\n",
      "Episode 132\tAverage Score: -42.39--------------------------------------\n",
      "| approxkl           | 0.0052636787  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 211           |\n",
      "| ep_reward_mean     | -61.4         |\n",
      "| explained_variance | 0.126         |\n",
      "| fps                | 1088          |\n",
      "| n_updates          | 76            |\n",
      "| policy_entropy     | 1.2466419     |\n",
      "| policy_loss        | -0.0042890245 |\n",
      "| serial_timesteps   | 19456         |\n",
      "| time_elapsed       | 21.8          |\n",
      "| total_timesteps    | 19456         |\n",
      "| value_loss         | 13.633709     |\n",
      "--------------------------------------\n",
      "Episode 133\tAverage Score: -42.74---------------------------------------\n",
      "| approxkl           | 0.0006236248   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 211            |\n",
      "| ep_reward_mean     | -61.4          |\n",
      "| explained_variance | 0.204          |\n",
      "| fps                | 1071           |\n",
      "| n_updates          | 77             |\n",
      "| policy_entropy     | 1.2383355      |\n",
      "| policy_loss        | -0.00052851473 |\n",
      "| serial_timesteps   | 19712          |\n",
      "| time_elapsed       | 22             |\n",
      "| total_timesteps    | 19712          |\n",
      "| value_loss         | 14.167746      |\n",
      "---------------------------------------\n",
      "Episode 136\tAverage Score: -43.32--------------------------------------\n",
      "| approxkl           | 0.0003908912  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 208           |\n",
      "| ep_reward_mean     | -60.6         |\n",
      "| explained_variance | 0.219         |\n",
      "| fps                | 1121          |\n",
      "| n_updates          | 78            |\n",
      "| policy_entropy     | 1.2512192     |\n",
      "| policy_loss        | -0.0019434443 |\n",
      "| serial_timesteps   | 19968         |\n",
      "| time_elapsed       | 22.2          |\n",
      "| total_timesteps    | 19968         |\n",
      "| value_loss         | 39.228153     |\n",
      "--------------------------------------\n",
      "Episode 140\tAverage Score: -42.42\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0020513705  |\n",
      "| clipfrac           | 0.0126953125  |\n",
      "| ep_len_mean        | 206           |\n",
      "| ep_reward_mean     | -60.3         |\n",
      "| explained_variance | 0.254         |\n",
      "| fps                | 1059          |\n",
      "| n_updates          | 79            |\n",
      "| policy_entropy     | 1.2884007     |\n",
      "| policy_loss        | -0.0036600688 |\n",
      "| serial_timesteps   | 20224         |\n",
      "| time_elapsed       | 22.5          |\n",
      "| total_timesteps    | 20224         |\n",
      "| value_loss         | 28.800484     |\n",
      "--------------------------------------\n",
      "Episode 142\tAverage Score: -40.60--------------------------------------\n",
      "| approxkl           | 0.0017611108  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 204           |\n",
      "| ep_reward_mean     | -59.8         |\n",
      "| explained_variance | 0.302         |\n",
      "| fps                | 1027          |\n",
      "| n_updates          | 80            |\n",
      "| policy_entropy     | 1.3528819     |\n",
      "| policy_loss        | -0.0008453893 |\n",
      "| serial_timesteps   | 20480         |\n",
      "| time_elapsed       | 22.7          |\n",
      "| total_timesteps    | 20480         |\n",
      "| value_loss         | 24.466457     |\n",
      "--------------------------------------\n",
      "Episode 143\tAverage Score: -38.37---------------------------------------\n",
      "| approxkl           | 0.00037054537  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 188            |\n",
      "| ep_reward_mean     | -53            |\n",
      "| explained_variance | 0.411          |\n",
      "| fps                | 1083           |\n",
      "| n_updates          | 81             |\n",
      "| policy_entropy     | 1.3724463      |\n",
      "| policy_loss        | -0.00037116063 |\n",
      "| serial_timesteps   | 20736          |\n",
      "| time_elapsed       | 23             |\n",
      "| total_timesteps    | 20736          |\n",
      "| value_loss         | 12.515767      |\n",
      "---------------------------------------\n",
      "Episode 145\tAverage Score: -39.44--------------------------------------\n",
      "| approxkl           | 0.0030439068  |\n",
      "| clipfrac           | 0.024414062   |\n",
      "| ep_len_mean        | 190           |\n",
      "| ep_reward_mean     | -53.5         |\n",
      "| explained_variance | 0.473         |\n",
      "| fps                | 1035          |\n",
      "| n_updates          | 82            |\n",
      "| policy_entropy     | 1.3705187     |\n",
      "| policy_loss        | -0.0047896607 |\n",
      "| serial_timesteps   | 20992         |\n",
      "| time_elapsed       | 23.2          |\n",
      "| total_timesteps    | 20992         |\n",
      "| value_loss         | 22.005314     |\n",
      "--------------------------------------\n",
      "Episode 150\tAverage Score: -37.77\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0033026098  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 186           |\n",
      "| ep_reward_mean     | -53           |\n",
      "| explained_variance | 0.425         |\n",
      "| fps                | 1061          |\n",
      "| n_updates          | 83            |\n",
      "| policy_entropy     | 1.3352937     |\n",
      "| policy_loss        | -0.0031051624 |\n",
      "| serial_timesteps   | 21248         |\n",
      "| time_elapsed       | 23.4          |\n",
      "| total_timesteps    | 21248         |\n",
      "| value_loss         | 33.699924     |\n",
      "--------------------------------------\n",
      "Episode 153\tAverage Score: -38.13-------------------------------------\n",
      "| approxkl           | 0.0008676415 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 185          |\n",
      "| ep_reward_mean     | -52.7        |\n",
      "| explained_variance | 0.55         |\n",
      "| fps                | 1047         |\n",
      "| n_updates          | 84           |\n",
      "| policy_entropy     | 1.3739964    |\n",
      "| policy_loss        | 0.0015028005 |\n",
      "| serial_timesteps   | 21504        |\n",
      "| time_elapsed       | 23.7         |\n",
      "| total_timesteps    | 21504        |\n",
      "| value_loss         | 30.329662    |\n",
      "-------------------------------------\n",
      "Episode 156\tAverage Score: -36.91--------------------------------------\n",
      "| approxkl           | 0.0023330392  |\n",
      "| clipfrac           | 0.0126953125  |\n",
      "| ep_len_mean        | 185           |\n",
      "| ep_reward_mean     | -52.7         |\n",
      "| explained_variance | 0.573         |\n",
      "| fps                | 1079          |\n",
      "| n_updates          | 85            |\n",
      "| policy_entropy     | 1.3605801     |\n",
      "| policy_loss        | -0.0020480938 |\n",
      "| serial_timesteps   | 21760         |\n",
      "| time_elapsed       | 23.9          |\n",
      "| total_timesteps    | 21760         |\n",
      "| value_loss         | 28.365866     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 161\tAverage Score: -32.87-------------------------------------\n",
      "| approxkl           | 0.002305938  |\n",
      "| clipfrac           | 0.0234375    |\n",
      "| ep_len_mean        | 184          |\n",
      "| ep_reward_mean     | -52.7        |\n",
      "| explained_variance | 0.516        |\n",
      "| fps                | 1098         |\n",
      "| n_updates          | 86           |\n",
      "| policy_entropy     | 1.3349429    |\n",
      "| policy_loss        | -0.009214844 |\n",
      "| serial_timesteps   | 22016        |\n",
      "| time_elapsed       | 24.2         |\n",
      "| total_timesteps    | 22016        |\n",
      "| value_loss         | 28.440609    |\n",
      "-------------------------------------\n",
      "Episode 165\tAverage Score: -33.01-------------------------------------\n",
      "| approxkl           | 0.003501359  |\n",
      "| clipfrac           | 0.0546875    |\n",
      "| ep_len_mean        | 184          |\n",
      "| ep_reward_mean     | -52.9        |\n",
      "| explained_variance | 0.653        |\n",
      "| fps                | 1089         |\n",
      "| n_updates          | 87           |\n",
      "| policy_entropy     | 1.2916284    |\n",
      "| policy_loss        | -0.005751361 |\n",
      "| serial_timesteps   | 22272        |\n",
      "| time_elapsed       | 24.4         |\n",
      "| total_timesteps    | 22272        |\n",
      "| value_loss         | 35.14365     |\n",
      "-------------------------------------\n",
      "Episode 170\tAverage Score: -33.02\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0052950447 |\n",
      "| clipfrac           | 0.0234375    |\n",
      "| ep_len_mean        | 183          |\n",
      "| ep_reward_mean     | -52.5        |\n",
      "| explained_variance | 0.663        |\n",
      "| fps                | 1106         |\n",
      "| n_updates          | 88           |\n",
      "| policy_entropy     | 1.342286     |\n",
      "| policy_loss        | -0.005204347 |\n",
      "| serial_timesteps   | 22528        |\n",
      "| time_elapsed       | 24.6         |\n",
      "| total_timesteps    | 22528        |\n",
      "| value_loss         | 44.91757     |\n",
      "-------------------------------------\n",
      "Episode 174\tAverage Score: -33.25-------------------------------------\n",
      "| approxkl           | 0.003593279  |\n",
      "| clipfrac           | 0.034179688  |\n",
      "| ep_len_mean        | 183          |\n",
      "| ep_reward_mean     | -52.7        |\n",
      "| explained_variance | 0.709        |\n",
      "| fps                | 974          |\n",
      "| n_updates          | 89           |\n",
      "| policy_entropy     | 1.3379874    |\n",
      "| policy_loss        | -0.008248672 |\n",
      "| serial_timesteps   | 22784        |\n",
      "| time_elapsed       | 24.9         |\n",
      "| total_timesteps    | 22784        |\n",
      "| value_loss         | 28.112246    |\n",
      "-------------------------------------\n",
      "Episode 177\tAverage Score: -33.29-------------------------------------\n",
      "| approxkl           | 0.005254116  |\n",
      "| clipfrac           | 0.056640625  |\n",
      "| ep_len_mean        | 158          |\n",
      "| ep_reward_mean     | -45.9        |\n",
      "| explained_variance | -0.155       |\n",
      "| fps                | 912          |\n",
      "| n_updates          | 90           |\n",
      "| policy_entropy     | 1.2217984    |\n",
      "| policy_loss        | 0.0029981248 |\n",
      "| serial_timesteps   | 23040        |\n",
      "| time_elapsed       | 25.1         |\n",
      "| total_timesteps    | 23040        |\n",
      "| value_loss         | 15.010946    |\n",
      "-------------------------------------\n",
      "Episode 180\tAverage Score: -33.37\n",
      "Episode 183\tAverage Score: -33.29-------------------------------------\n",
      "| approxkl           | 0.0064915745 |\n",
      "| clipfrac           | 0.08105469   |\n",
      "| ep_len_mean        | 150          |\n",
      "| ep_reward_mean     | -44          |\n",
      "| explained_variance | 0.712        |\n",
      "| fps                | 912          |\n",
      "| n_updates          | 91           |\n",
      "| policy_entropy     | 1.1028177    |\n",
      "| policy_loss        | -0.005700987 |\n",
      "| serial_timesteps   | 23296        |\n",
      "| time_elapsed       | 25.4         |\n",
      "| total_timesteps    | 23296        |\n",
      "| value_loss         | 43.21562     |\n",
      "-------------------------------------\n",
      "Episode 184\tAverage Score: -33.22--------------------------------------\n",
      "| approxkl           | 0.00061806303 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 150           |\n",
      "| ep_reward_mean     | -44           |\n",
      "| explained_variance | 0.0654        |\n",
      "| fps                | 1095          |\n",
      "| n_updates          | 92            |\n",
      "| policy_entropy     | 1.0903447     |\n",
      "| policy_loss        | 0.00035549374 |\n",
      "| serial_timesteps   | 23552         |\n",
      "| time_elapsed       | 25.7          |\n",
      "| total_timesteps    | 23552         |\n",
      "| value_loss         | 9.4808655     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0025494262  |\n",
      "| clipfrac           | 0.041015625   |\n",
      "| ep_len_mean        | 150           |\n",
      "| ep_reward_mean     | -44           |\n",
      "| explained_variance | -0.00963      |\n",
      "| fps                | 1116          |\n",
      "| n_updates          | 93            |\n",
      "| policy_entropy     | 1.0585028     |\n",
      "| policy_loss        | -0.0029124317 |\n",
      "| serial_timesteps   | 23808         |\n",
      "| time_elapsed       | 25.9          |\n",
      "| total_timesteps    | 23808         |\n",
      "| value_loss         | 0.9524235     |\n",
      "--------------------------------------\n",
      "Episode 187\tAverage Score: -34.46--------------------------------------\n",
      "| approxkl           | 0.00059120974 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 130           |\n",
      "| ep_reward_mean     | -38.8         |\n",
      "| explained_variance | -0.064        |\n",
      "| fps                | 1097          |\n",
      "| n_updates          | 94            |\n",
      "| policy_entropy     | 0.9791065     |\n",
      "| policy_loss        | 0.0021448843  |\n",
      "| serial_timesteps   | 24064         |\n",
      "| time_elapsed       | 26.2          |\n",
      "| total_timesteps    | 24064         |\n",
      "| value_loss         | 9.961781      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000973398   |\n",
      "| clipfrac           | 0.0009765625  |\n",
      "| ep_len_mean        | 130           |\n",
      "| ep_reward_mean     | -38.8         |\n",
      "| explained_variance | -2.63         |\n",
      "| fps                | 1108          |\n",
      "| n_updates          | 95            |\n",
      "| policy_entropy     | 0.99328697    |\n",
      "| policy_loss        | -0.0018650579 |\n",
      "| serial_timesteps   | 24320         |\n",
      "| time_elapsed       | 26.4          |\n",
      "| total_timesteps    | 24320         |\n",
      "| value_loss         | 0.8806312     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0016758512   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 130            |\n",
      "| ep_reward_mean     | -38.8          |\n",
      "| explained_variance | -0.043         |\n",
      "| fps                | 1148           |\n",
      "| n_updates          | 96             |\n",
      "| policy_entropy     | 0.9950973      |\n",
      "| policy_loss        | -0.00079382805 |\n",
      "| serial_timesteps   | 24576          |\n",
      "| time_elapsed       | 26.6           |\n",
      "| total_timesteps    | 24576          |\n",
      "| value_loss         | 0.5563522      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.007866695   |\n",
      "| clipfrac           | 0.115234375   |\n",
      "| ep_len_mean        | 130           |\n",
      "| ep_reward_mean     | -38.8         |\n",
      "| explained_variance | 0.00739       |\n",
      "| fps                | 1179          |\n",
      "| n_updates          | 97            |\n",
      "| policy_entropy     | 0.876789      |\n",
      "| policy_loss        | -0.0052550174 |\n",
      "| serial_timesteps   | 24832         |\n",
      "| time_elapsed       | 26.8          |\n",
      "| total_timesteps    | 24832         |\n",
      "| value_loss         | 0.47407544    |\n",
      "--------------------------------------\n",
      "Episode 189\tAverage Score: -36.36---------------------------------------\n",
      "| approxkl           | 0.0005647327   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 130            |\n",
      "| ep_reward_mean     | -38.8          |\n",
      "| explained_variance | 0.166          |\n",
      "| fps                | 1168           |\n",
      "| n_updates          | 98             |\n",
      "| policy_entropy     | 0.8777466      |\n",
      "| policy_loss        | -0.00095394324 |\n",
      "| serial_timesteps   | 25088          |\n",
      "| time_elapsed       | 27.1           |\n",
      "| total_timesteps    | 25088          |\n",
      "| value_loss         | 3.05568        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016232496  |\n",
      "| clipfrac           | 0.0107421875  |\n",
      "| ep_len_mean        | 130           |\n",
      "| ep_reward_mean     | -38.8         |\n",
      "| explained_variance | -0.0241       |\n",
      "| fps                | 1076          |\n",
      "| n_updates          | 99            |\n",
      "| policy_entropy     | 0.90788007    |\n",
      "| policy_loss        | 0.00026258884 |\n",
      "| serial_timesteps   | 25344         |\n",
      "| time_elapsed       | 27.3          |\n",
      "| total_timesteps    | 25344         |\n",
      "| value_loss         | 0.41854993    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| approxkl           | 0.0015802946 |\n",
      "| clipfrac           | 0.0009765625 |\n",
      "| ep_len_mean        | 130          |\n",
      "| ep_reward_mean     | -38.8        |\n",
      "| explained_variance | -0.0141      |\n",
      "| fps                | 1046         |\n",
      "| n_updates          | 100          |\n",
      "| policy_entropy     | 0.85782903   |\n",
      "| policy_loss        | 0.002058557  |\n",
      "| serial_timesteps   | 25600        |\n",
      "| time_elapsed       | 27.5         |\n",
      "| total_timesteps    | 25600        |\n",
      "| value_loss         | 0.33001822   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0026865466  |\n",
      "| clipfrac           | 0.033203125   |\n",
      "| ep_len_mean        | 130           |\n",
      "| ep_reward_mean     | -38.8         |\n",
      "| explained_variance | -0.0702       |\n",
      "| fps                | 1005          |\n",
      "| n_updates          | 101           |\n",
      "| policy_entropy     | 0.9529283     |\n",
      "| policy_loss        | -0.0023391126 |\n",
      "| serial_timesteps   | 25856         |\n",
      "| time_elapsed       | 27.8          |\n",
      "| total_timesteps    | 25856         |\n",
      "| value_loss         | 0.28003165    |\n",
      "--------------------------------------\n",
      "Episode 193\tAverage Score: -38.55--------------------------------------\n",
      "| approxkl           | 0.0006385819  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 149           |\n",
      "| ep_reward_mean     | -43.7         |\n",
      "| explained_variance | 0.17          |\n",
      "| fps                | 980           |\n",
      "| n_updates          | 102           |\n",
      "| policy_entropy     | 0.9855909     |\n",
      "| policy_loss        | -0.0010801563 |\n",
      "| serial_timesteps   | 26112         |\n",
      "| time_elapsed       | 28            |\n",
      "| total_timesteps    | 26112         |\n",
      "| value_loss         | 19.901646     |\n",
      "--------------------------------------\n",
      "Episode 194\tAverage Score: -38.52-------------------------------------\n",
      "| approxkl           | 0.0011076798 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 149          |\n",
      "| ep_reward_mean     | -43.7        |\n",
      "| explained_variance | 0.113        |\n",
      "| fps                | 1098         |\n",
      "| n_updates          | 103          |\n",
      "| policy_entropy     | 1.0110835    |\n",
      "| policy_loss        | -0.005924067 |\n",
      "| serial_timesteps   | 26368        |\n",
      "| time_elapsed       | 28.3         |\n",
      "| total_timesteps    | 26368        |\n",
      "| value_loss         | 8.5536       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0065142615  |\n",
      "| clipfrac           | 0.11328125    |\n",
      "| ep_len_mean        | 149           |\n",
      "| ep_reward_mean     | -43.7         |\n",
      "| explained_variance | -0.115        |\n",
      "| fps                | 1121          |\n",
      "| n_updates          | 104           |\n",
      "| policy_entropy     | 1.086757      |\n",
      "| policy_loss        | -0.0031576923 |\n",
      "| serial_timesteps   | 26624         |\n",
      "| time_elapsed       | 28.5          |\n",
      "| total_timesteps    | 26624         |\n",
      "| value_loss         | 0.21815325    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.005353328  |\n",
      "| clipfrac           | 0.0625       |\n",
      "| ep_len_mean        | 149          |\n",
      "| ep_reward_mean     | -43.7        |\n",
      "| explained_variance | 0.0671       |\n",
      "| fps                | 1122         |\n",
      "| n_updates          | 105          |\n",
      "| policy_entropy     | 1.1215539    |\n",
      "| policy_loss        | -0.004340258 |\n",
      "| serial_timesteps   | 26880        |\n",
      "| time_elapsed       | 28.7         |\n",
      "| total_timesteps    | 26880        |\n",
      "| value_loss         | 0.19545916   |\n",
      "-------------------------------------\n",
      "Episode 196\tAverage Score: -40.35---------------------------------------\n",
      "| approxkl           | 0.0020810934   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 149            |\n",
      "| ep_reward_mean     | -43.7          |\n",
      "| explained_variance | 0.336          |\n",
      "| fps                | 1105           |\n",
      "| n_updates          | 106            |\n",
      "| policy_entropy     | 1.1631206      |\n",
      "| policy_loss        | -0.00072304986 |\n",
      "| serial_timesteps   | 27136          |\n",
      "| time_elapsed       | 29             |\n",
      "| total_timesteps    | 27136          |\n",
      "| value_loss         | 1.2678076      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.013904696  |\n",
      "| clipfrac           | 0.27441406   |\n",
      "| ep_len_mean        | 149          |\n",
      "| ep_reward_mean     | -43.7        |\n",
      "| explained_variance | -0.109       |\n",
      "| fps                | 1110         |\n",
      "| n_updates          | 107          |\n",
      "| policy_entropy     | 1.2308708    |\n",
      "| policy_loss        | -0.016203664 |\n",
      "| serial_timesteps   | 27392        |\n",
      "| time_elapsed       | 29.2         |\n",
      "| total_timesteps    | 27392        |\n",
      "| value_loss         | 0.25225884   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0077527426 |\n",
      "| clipfrac           | 0.16699219   |\n",
      "| ep_len_mean        | 149          |\n",
      "| ep_reward_mean     | -43.7        |\n",
      "| explained_variance | 0.00177      |\n",
      "| fps                | 1129         |\n",
      "| n_updates          | 108          |\n",
      "| policy_entropy     | 1.2671127    |\n",
      "| policy_loss        | -0.013790345 |\n",
      "| serial_timesteps   | 27648        |\n",
      "| time_elapsed       | 29.4         |\n",
      "| total_timesteps    | 27648        |\n",
      "| value_loss         | 0.21827903   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.01374495   |\n",
      "| clipfrac           | 0.2685547    |\n",
      "| ep_len_mean        | 149          |\n",
      "| ep_reward_mean     | -43.7        |\n",
      "| explained_variance | 0.413        |\n",
      "| fps                | 1031         |\n",
      "| n_updates          | 109          |\n",
      "| policy_entropy     | 1.2893054    |\n",
      "| policy_loss        | -0.027771907 |\n",
      "| serial_timesteps   | 27904        |\n",
      "| time_elapsed       | 29.7         |\n",
      "| total_timesteps    | 27904        |\n",
      "| value_loss         | 0.14213198   |\n",
      "-------------------------------------\n",
      "Episode 200\tAverage Score: -42.40\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004236779  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 167           |\n",
      "| ep_reward_mean     | -48.1         |\n",
      "| explained_variance | 0.271         |\n",
      "| fps                | 954           |\n",
      "| n_updates          | 110           |\n",
      "| policy_entropy     | 1.2897067     |\n",
      "| policy_loss        | -0.0016103872 |\n",
      "| serial_timesteps   | 28160         |\n",
      "| time_elapsed       | 29.9          |\n",
      "| total_timesteps    | 28160         |\n",
      "| value_loss         | 17.891212     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0032822706  |\n",
      "| clipfrac           | 0.024414062   |\n",
      "| ep_len_mean        | 167           |\n",
      "| ep_reward_mean     | -48.1         |\n",
      "| explained_variance | -0.496        |\n",
      "| fps                | 839           |\n",
      "| n_updates          | 111           |\n",
      "| policy_entropy     | 1.33106       |\n",
      "| policy_loss        | -0.0007802112 |\n",
      "| serial_timesteps   | 28416         |\n",
      "| time_elapsed       | 30.2          |\n",
      "| total_timesteps    | 28416         |\n",
      "| value_loss         | 5.9388857     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0064815693 |\n",
      "| clipfrac           | 0.1015625    |\n",
      "| ep_len_mean        | 167          |\n",
      "| ep_reward_mean     | -48.1        |\n",
      "| explained_variance | -0.308       |\n",
      "| fps                | 1069         |\n",
      "| n_updates          | 112          |\n",
      "| policy_entropy     | 1.310229     |\n",
      "| policy_loss        | -0.008213345 |\n",
      "| serial_timesteps   | 28672        |\n",
      "| time_elapsed       | 30.5         |\n",
      "| total_timesteps    | 28672        |\n",
      "| value_loss         | 5.1645546    |\n",
      "-------------------------------------\n",
      "Episode 201\tAverage Score: -45.10--------------------------------------\n",
      "| approxkl           | 0.0026025942  |\n",
      "| clipfrac           | 0.0068359375  |\n",
      "| ep_len_mean        | 175           |\n",
      "| ep_reward_mean     | -50.8         |\n",
      "| explained_variance | 0.113         |\n",
      "| fps                | 1069          |\n",
      "| n_updates          | 113           |\n",
      "| policy_entropy     | 1.2811729     |\n",
      "| policy_loss        | -0.0066365562 |\n",
      "| serial_timesteps   | 28928         |\n",
      "| time_elapsed       | 30.7          |\n",
      "| total_timesteps    | 28928         |\n",
      "| value_loss         | 9.134148      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 204\tAverage Score: -45.19--------------------------------------\n",
      "| approxkl           | 0.0011485969  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 177           |\n",
      "| ep_reward_mean     | -51.3         |\n",
      "| explained_variance | 0.258         |\n",
      "| fps                | 1029          |\n",
      "| n_updates          | 114           |\n",
      "| policy_entropy     | 1.2577662     |\n",
      "| policy_loss        | -0.0007126813 |\n",
      "| serial_timesteps   | 29184         |\n",
      "| time_elapsed       | 31            |\n",
      "| total_timesteps    | 29184         |\n",
      "| value_loss         | 10.251055     |\n",
      "--------------------------------------\n",
      "Episode 206\tAverage Score: -45.39--------------------------------------\n",
      "| approxkl           | 0.00044100324 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 178           |\n",
      "| ep_reward_mean     | -51.6         |\n",
      "| explained_variance | 0.414         |\n",
      "| fps                | 977           |\n",
      "| n_updates          | 115           |\n",
      "| policy_entropy     | 1.2504132     |\n",
      "| policy_loss        | -0.0023037645 |\n",
      "| serial_timesteps   | 29440         |\n",
      "| time_elapsed       | 31.2          |\n",
      "| total_timesteps    | 29440         |\n",
      "| value_loss         | 16.455624     |\n",
      "--------------------------------------\n",
      "Episode 209\tAverage Score: -46.01--------------------------------------\n",
      "| approxkl           | 0.0009990187  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 180           |\n",
      "| ep_reward_mean     | -52.1         |\n",
      "| explained_variance | 0.517         |\n",
      "| fps                | 981           |\n",
      "| n_updates          | 116           |\n",
      "| policy_entropy     | 1.2327678     |\n",
      "| policy_loss        | -0.0008155553 |\n",
      "| serial_timesteps   | 29696         |\n",
      "| time_elapsed       | 31.5          |\n",
      "| total_timesteps    | 29696         |\n",
      "| value_loss         | 22.158447     |\n",
      "--------------------------------------\n",
      "Episode 210\tAverage Score: -46.10\n",
      "Episode 213\tAverage Score: -46.16-------------------------------------\n",
      "| approxkl           | 0.007928761  |\n",
      "| clipfrac           | 0.1640625    |\n",
      "| ep_len_mean        | 181          |\n",
      "| ep_reward_mean     | -52.2        |\n",
      "| explained_variance | 0.547        |\n",
      "| fps                | 945          |\n",
      "| n_updates          | 117          |\n",
      "| policy_entropy     | 1.208793     |\n",
      "| policy_loss        | -0.013681997 |\n",
      "| serial_timesteps   | 29952        |\n",
      "| time_elapsed       | 31.7         |\n",
      "| total_timesteps    | 29952        |\n",
      "| value_loss         | 29.060987    |\n",
      "-------------------------------------\n",
      "Episode 219\tAverage Score: -45.88--------------------------------------\n",
      "| approxkl           | 0.0012078711  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 180           |\n",
      "| ep_reward_mean     | -52           |\n",
      "| explained_variance | 0.598         |\n",
      "| fps                | 938           |\n",
      "| n_updates          | 118           |\n",
      "| policy_entropy     | 1.2058704     |\n",
      "| policy_loss        | 0.00040852395 |\n",
      "| serial_timesteps   | 30208         |\n",
      "| time_elapsed       | 32            |\n",
      "| total_timesteps    | 30208         |\n",
      "| value_loss         | 29.009407     |\n",
      "--------------------------------------\n",
      "Episode 220\tAverage Score: -46.05\n",
      "Episode 224\tAverage Score: -41.78-------------------------------------\n",
      "| approxkl           | 0.0027697932 |\n",
      "| clipfrac           | 0.044921875  |\n",
      "| ep_len_mean        | 180          |\n",
      "| ep_reward_mean     | -51.8        |\n",
      "| explained_variance | 0.638        |\n",
      "| fps                | 1006         |\n",
      "| n_updates          | 119          |\n",
      "| policy_entropy     | 1.1960309    |\n",
      "| policy_loss        | -0.007463964 |\n",
      "| serial_timesteps   | 30464        |\n",
      "| time_elapsed       | 32.3         |\n",
      "| total_timesteps    | 30464        |\n",
      "| value_loss         | 30.886093    |\n",
      "-------------------------------------\n",
      "Episode 229\tAverage Score: -35.55--------------------------------------\n",
      "| approxkl           | 0.0033376042  |\n",
      "| clipfrac           | 0.0126953125  |\n",
      "| ep_len_mean        | 179           |\n",
      "| ep_reward_mean     | -51.7         |\n",
      "| explained_variance | 0.647         |\n",
      "| fps                | 1019          |\n",
      "| n_updates          | 120           |\n",
      "| policy_entropy     | 1.1064827     |\n",
      "| policy_loss        | -0.0035491595 |\n",
      "| serial_timesteps   | 30720         |\n",
      "| time_elapsed       | 32.5          |\n",
      "| total_timesteps    | 30720         |\n",
      "| value_loss         | 34.652626     |\n",
      "--------------------------------------\n",
      "Episode 230\tAverage Score: -35.10\n",
      "Episode 235\tAverage Score: -32.77---------------------------------------\n",
      "| approxkl           | 0.00096093613  |\n",
      "| clipfrac           | 0.00390625     |\n",
      "| ep_len_mean        | 178            |\n",
      "| ep_reward_mean     | -51.4          |\n",
      "| explained_variance | 0.66           |\n",
      "| fps                | 1021           |\n",
      "| n_updates          | 121            |\n",
      "| policy_entropy     | 1.053343       |\n",
      "| policy_loss        | -0.00014680368 |\n",
      "| serial_timesteps   | 30976          |\n",
      "| time_elapsed       | 32.8           |\n",
      "| total_timesteps    | 30976          |\n",
      "| value_loss         | 37.647385      |\n",
      "---------------------------------------\n",
      "Episode 240\tAverage Score: -32.14\n",
      "Episode 241\tAverage Score: -31.90--------------------------------------\n",
      "| approxkl           | 0.0057176426  |\n",
      "| clipfrac           | 0.046875      |\n",
      "| ep_len_mean        | 179           |\n",
      "| ep_reward_mean     | -51.4         |\n",
      "| explained_variance | 0.643         |\n",
      "| fps                | 715           |\n",
      "| n_updates          | 122           |\n",
      "| policy_entropy     | 1.1059165     |\n",
      "| policy_loss        | -0.0025481842 |\n",
      "| serial_timesteps   | 31232         |\n",
      "| time_elapsed       | 33            |\n",
      "| total_timesteps    | 31232         |\n",
      "| value_loss         | 23.262718     |\n",
      "--------------------------------------\n",
      "Episode 247\tAverage Score: -30.36-------------------------------------\n",
      "| approxkl           | 0.009024334  |\n",
      "| clipfrac           | 0.12011719   |\n",
      "| ep_len_mean        | 178          |\n",
      "| ep_reward_mean     | -51.3        |\n",
      "| explained_variance | 0.754        |\n",
      "| fps                | 951          |\n",
      "| n_updates          | 123          |\n",
      "| policy_entropy     | 1.0958811    |\n",
      "| policy_loss        | -0.012212319 |\n",
      "| serial_timesteps   | 31488        |\n",
      "| time_elapsed       | 33.4         |\n",
      "| total_timesteps    | 31488        |\n",
      "| value_loss         | 32.954716    |\n",
      "-------------------------------------\n",
      "Episode 250\tAverage Score: -29.92\n",
      "Episode 251\tAverage Score: -29.77-------------------------------------\n",
      "| approxkl           | 0.0015428376 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 178          |\n",
      "| ep_reward_mean     | -51.2        |\n",
      "| explained_variance | 0.571        |\n",
      "| fps                | 968          |\n",
      "| n_updates          | 124          |\n",
      "| policy_entropy     | 1.0636643    |\n",
      "| policy_loss        | 0.0022095565 |\n",
      "| serial_timesteps   | 31744        |\n",
      "| time_elapsed       | 33.7         |\n",
      "| total_timesteps    | 31744        |\n",
      "| value_loss         | 21.652111    |\n",
      "-------------------------------------\n",
      "Episode 253\tAverage Score: -30.23---------------------------------------\n",
      "| approxkl           | 0.00056027476  |\n",
      "| clipfrac           | 0.0009765625   |\n",
      "| ep_len_mean        | 178            |\n",
      "| ep_reward_mean     | -51.2          |\n",
      "| explained_variance | -0.0126        |\n",
      "| fps                | 1057           |\n",
      "| n_updates          | 125            |\n",
      "| policy_entropy     | 1.0805979      |\n",
      "| policy_loss        | -0.00033961335 |\n",
      "| serial_timesteps   | 32000          |\n",
      "| time_elapsed       | 33.9           |\n",
      "| total_timesteps    | 32000          |\n",
      "| value_loss         | 1.4551334      |\n",
      "---------------------------------------\n",
      "Episode 258\tAverage Score: -29.58-------------------------------------\n",
      "| approxkl           | 0.003252585  |\n",
      "| clipfrac           | 0.05078125   |\n",
      "| ep_len_mean        | 128          |\n",
      "| ep_reward_mean     | -37.9        |\n",
      "| explained_variance | 0.607        |\n",
      "| fps                | 1027         |\n",
      "| n_updates          | 126          |\n",
      "| policy_entropy     | 1.1322715    |\n",
      "| policy_loss        | -0.004350937 |\n",
      "| serial_timesteps   | 32256        |\n",
      "| time_elapsed       | 34.2         |\n",
      "| total_timesteps    | 32256        |\n",
      "| value_loss         | 29.217436    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00049422437 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 128           |\n",
      "| ep_reward_mean     | -37.9         |\n",
      "| explained_variance | 0.123         |\n",
      "| fps                | 1090          |\n",
      "| n_updates          | 127           |\n",
      "| policy_entropy     | 1.1708647     |\n",
      "| policy_loss        | -0.0023931891 |\n",
      "| serial_timesteps   | 32512         |\n",
      "| time_elapsed       | 34.4          |\n",
      "| total_timesteps    | 32512         |\n",
      "| value_loss         | 1.2731258     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0049090916  |\n",
      "| clipfrac           | 0.099609375   |\n",
      "| ep_len_mean        | 128           |\n",
      "| ep_reward_mean     | -37.9         |\n",
      "| explained_variance | -0.00243      |\n",
      "| fps                | 1123          |\n",
      "| n_updates          | 128           |\n",
      "| policy_entropy     | 1.121363      |\n",
      "| policy_loss        | -0.0046243584 |\n",
      "| serial_timesteps   | 32768         |\n",
      "| time_elapsed       | 34.7          |\n",
      "| total_timesteps    | 32768         |\n",
      "| value_loss         | 0.9568459     |\n",
      "--------------------------------------\n",
      "Episode 260\tAverage Score: -31.05\n",
      "Episode 260\tAverage Score: -31.05\n",
      "--------------------------------------\n",
      "| approxkl           | 0.006082      |\n",
      "| clipfrac           | 0.10644531    |\n",
      "| ep_len_mean        | 128           |\n",
      "| ep_reward_mean     | -37.9         |\n",
      "| explained_variance | 0.34          |\n",
      "| fps                | 988           |\n",
      "| n_updates          | 129           |\n",
      "| policy_entropy     | 1.1381837     |\n",
      "| policy_loss        | -0.0066286707 |\n",
      "| serial_timesteps   | 33024         |\n",
      "| time_elapsed       | 34.9          |\n",
      "| total_timesteps    | 33024         |\n",
      "| value_loss         | 3.2195637     |\n",
      "--------------------------------------\n",
      "Episode 265\tAverage Score: -30.94-------------------------------------\n",
      "| approxkl           | 0.004015618  |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| ep_len_mean        | 132          |\n",
      "| ep_reward_mean     | -38.3        |\n",
      "| explained_variance | 0.699        |\n",
      "| fps                | 985          |\n",
      "| n_updates          | 130          |\n",
      "| policy_entropy     | 1.1272974    |\n",
      "| policy_loss        | -0.001892068 |\n",
      "| serial_timesteps   | 33280        |\n",
      "| time_elapsed       | 35.2         |\n",
      "| total_timesteps    | 33280        |\n",
      "| value_loss         | 25.454441    |\n",
      "-------------------------------------\n",
      "Episode 270\tAverage Score: -30.83\n",
      "Episode 271\tAverage Score: -30.77-------------------------------------\n",
      "| approxkl           | 0.0029634258 |\n",
      "| clipfrac           | 0.03515625   |\n",
      "| ep_len_mean        | 126          |\n",
      "| ep_reward_mean     | -36.4        |\n",
      "| explained_variance | 0.659        |\n",
      "| fps                | 1034         |\n",
      "| n_updates          | 131          |\n",
      "| policy_entropy     | 1.1068804    |\n",
      "| policy_loss        | -0.004236932 |\n",
      "| serial_timesteps   | 33536        |\n",
      "| time_elapsed       | 35.4         |\n",
      "| total_timesteps    | 33536        |\n",
      "| value_loss         | 25.43701     |\n",
      "-------------------------------------\n",
      "Episode 276\tAverage Score: -30.13-------------------------------------\n",
      "| approxkl           | 0.005211201  |\n",
      "| clipfrac           | 0.021484375  |\n",
      "| ep_len_mean        | 124          |\n",
      "| ep_reward_mean     | -35.4        |\n",
      "| explained_variance | 0.694        |\n",
      "| fps                | 1042         |\n",
      "| n_updates          | 132          |\n",
      "| policy_entropy     | 1.0505989    |\n",
      "| policy_loss        | -0.004564196 |\n",
      "| serial_timesteps   | 33792        |\n",
      "| time_elapsed       | 35.7         |\n",
      "| total_timesteps    | 33792        |\n",
      "| value_loss         | 21.00111     |\n",
      "-------------------------------------\n",
      "Episode 280\tAverage Score: -30.16\n",
      "Episode 283\tAverage Score: -30.01--------------------------------------\n",
      "| approxkl           | 0.0022259029  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 122           |\n",
      "| ep_reward_mean     | -34.6         |\n",
      "| explained_variance | 0.556         |\n",
      "| fps                | 1023          |\n",
      "| n_updates          | 133           |\n",
      "| policy_entropy     | 1.0001434     |\n",
      "| policy_loss        | -0.0051516243 |\n",
      "| serial_timesteps   | 34048         |\n",
      "| time_elapsed       | 35.9          |\n",
      "| total_timesteps    | 34048         |\n",
      "| value_loss         | 22.819263     |\n",
      "--------------------------------------\n",
      "Episode 290\tAverage Score: -24.11\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00040831362 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 120           |\n",
      "| ep_reward_mean     | -33.9         |\n",
      "| explained_variance | 0.735         |\n",
      "| fps                | 980           |\n",
      "| n_updates          | 134           |\n",
      "| policy_entropy     | 0.9694876     |\n",
      "| policy_loss        | 0.00024824392 |\n",
      "| serial_timesteps   | 34304         |\n",
      "| time_elapsed       | 36.2          |\n",
      "| total_timesteps    | 34304         |\n",
      "| value_loss         | 27.239296     |\n",
      "--------------------------------------\n",
      "Episode 294\tAverage Score: -24.08--------------------------------------\n",
      "| approxkl           | 0.00042595426 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 119           |\n",
      "| ep_reward_mean     | -33.8         |\n",
      "| explained_variance | 0.474         |\n",
      "| fps                | 851           |\n",
      "| n_updates          | 135           |\n",
      "| policy_entropy     | 0.9812514     |\n",
      "| policy_loss        | -0.0009750305 |\n",
      "| serial_timesteps   | 34560         |\n",
      "| time_elapsed       | 36.4          |\n",
      "| total_timesteps    | 34560         |\n",
      "| value_loss         | 15.742403     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0006911809   |\n",
      "| clipfrac           | 0.001953125    |\n",
      "| ep_len_mean        | 119            |\n",
      "| ep_reward_mean     | -33.8          |\n",
      "| explained_variance | -0.0394        |\n",
      "| fps                | 1056           |\n",
      "| n_updates          | 136            |\n",
      "| policy_entropy     | 0.9803853      |\n",
      "| policy_loss        | -0.00039176154 |\n",
      "| serial_timesteps   | 34816          |\n",
      "| time_elapsed       | 36.7           |\n",
      "| total_timesteps    | 34816          |\n",
      "| value_loss         | 1.36488        |\n",
      "---------------------------------------\n",
      "Episode 297\tAverage Score: -21.16--------------------------------------\n",
      "| approxkl           | 0.00077596726 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 125           |\n",
      "| ep_reward_mean     | -35.2         |\n",
      "| explained_variance | 0.0357        |\n",
      "| fps                | 1041          |\n",
      "| n_updates          | 137           |\n",
      "| policy_entropy     | 0.96416       |\n",
      "| policy_loss        | -0.0003575664 |\n",
      "| serial_timesteps   | 35072         |\n",
      "| time_elapsed       | 37            |\n",
      "| total_timesteps    | 35072         |\n",
      "| value_loss         | 6.5378203     |\n",
      "--------------------------------------\n",
      "Episode 300\tAverage Score: -21.26\n",
      "Episode 304\tAverage Score: -18.12-------------------------------------\n",
      "| approxkl           | 0.006733657  |\n",
      "| clipfrac           | 0.091796875  |\n",
      "| ep_len_mean        | 122          |\n",
      "| ep_reward_mean     | -34.2        |\n",
      "| explained_variance | 0.721        |\n",
      "| fps                | 961          |\n",
      "| n_updates          | 138          |\n",
      "| policy_entropy     | 0.96388495   |\n",
      "| policy_loss        | -0.011069822 |\n",
      "| serial_timesteps   | 35328        |\n",
      "| time_elapsed       | 37.2         |\n",
      "| total_timesteps    | 35328        |\n",
      "| value_loss         | 24.269165    |\n",
      "-------------------------------------\n",
      "Episode 306\tAverage Score: -17.89--------------------------------------\n",
      "| approxkl           | 0.00045590044 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 122           |\n",
      "| ep_reward_mean     | -34.2         |\n",
      "| explained_variance | 0.13          |\n",
      "| fps                | 964           |\n",
      "| n_updates          | 139           |\n",
      "| policy_entropy     | 0.9452629     |\n",
      "| policy_loss        | -0.000951772  |\n",
      "| serial_timesteps   | 35584         |\n",
      "| time_elapsed       | 37.5          |\n",
      "| total_timesteps    | 35584         |\n",
      "| value_loss         | 9.017443      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0016128811  |\n",
      "| clipfrac           | 0.018554688   |\n",
      "| ep_len_mean        | 122           |\n",
      "| ep_reward_mean     | -34.2         |\n",
      "| explained_variance | -0.00817      |\n",
      "| fps                | 1101          |\n",
      "| n_updates          | 140           |\n",
      "| policy_entropy     | 0.93921936    |\n",
      "| policy_loss        | -0.0041608354 |\n",
      "| serial_timesteps   | 35840         |\n",
      "| time_elapsed       | 37.7          |\n",
      "| total_timesteps    | 35840         |\n",
      "| value_loss         | 1.3888847     |\n",
      "--------------------------------------\n",
      "Episode 310\tAverage Score: -18.38\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0018302706 |\n",
      "| clipfrac           | 0.0009765625 |\n",
      "| ep_len_mean        | 128          |\n",
      "| ep_reward_mean     | -35.8        |\n",
      "| explained_variance | 0.351        |\n",
      "| fps                | 1069         |\n",
      "| n_updates          | 141          |\n",
      "| policy_entropy     | 0.9578048    |\n",
      "| policy_loss        | 0.0016513894 |\n",
      "| serial_timesteps   | 36096        |\n",
      "| time_elapsed       | 38           |\n",
      "| total_timesteps    | 36096        |\n",
      "| value_loss         | 8.610982     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 316\tAverage Score: -18.43---------------------------------------\n",
      "| approxkl           | 0.0006822573   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 82.7           |\n",
      "| ep_reward_mean     | -24.6          |\n",
      "| explained_variance | 0.627          |\n",
      "| fps                | 1047           |\n",
      "| n_updates          | 142            |\n",
      "| policy_entropy     | 0.98875993     |\n",
      "| policy_loss        | -0.00049314176 |\n",
      "| serial_timesteps   | 36352          |\n",
      "| time_elapsed       | 38.2           |\n",
      "| total_timesteps    | 36352          |\n",
      "| value_loss         | 19.525593      |\n",
      "---------------------------------------\n",
      "Episode 318\tAverage Score: -18.39--------------------------------------\n",
      "| approxkl           | 0.00053145067 |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| ep_len_mean        | 73.3          |\n",
      "| ep_reward_mean     | -21.3         |\n",
      "| explained_variance | 0.294         |\n",
      "| fps                | 1038          |\n",
      "| n_updates          | 143           |\n",
      "| policy_entropy     | 0.9949555     |\n",
      "| policy_loss        | -0.0039476138 |\n",
      "| serial_timesteps   | 36608         |\n",
      "| time_elapsed       | 38.5          |\n",
      "| total_timesteps    | 36608         |\n",
      "| value_loss         | 6.966976      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.007845521  |\n",
      "| clipfrac           | 0.18066406   |\n",
      "| ep_len_mean        | 73.3         |\n",
      "| ep_reward_mean     | -21.3        |\n",
      "| explained_variance | -0.0366      |\n",
      "| fps                | 1105         |\n",
      "| n_updates          | 144          |\n",
      "| policy_entropy     | 1.0198202    |\n",
      "| policy_loss        | -0.007286485 |\n",
      "| serial_timesteps   | 36864        |\n",
      "| time_elapsed       | 38.7         |\n",
      "| total_timesteps    | 36864        |\n",
      "| value_loss         | 1.1232253    |\n",
      "-------------------------------------\n",
      "Episode 320\tAverage Score: -19.60\n",
      "Episode 320\tAverage Score: -19.60\n",
      "Episode 323\tAverage Score: -19.42--------------------------------------\n",
      "| approxkl           | 0.00051994517 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 76.3          |\n",
      "| ep_reward_mean     | -22.1         |\n",
      "| explained_variance | 0.399         |\n",
      "| fps                | 1003          |\n",
      "| n_updates          | 145           |\n",
      "| policy_entropy     | 1.08204       |\n",
      "| policy_loss        | 0.0002761776  |\n",
      "| serial_timesteps   | 37120         |\n",
      "| time_elapsed       | 38.9          |\n",
      "| total_timesteps    | 37120         |\n",
      "| value_loss         | 11.38678      |\n",
      "--------------------------------------\n",
      "Episode 328\tAverage Score: -19.42--------------------------------------\n",
      "| approxkl           | 0.00012397533 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 74.4          |\n",
      "| ep_reward_mean     | -21.7         |\n",
      "| explained_variance | 0.639         |\n",
      "| fps                | 1054          |\n",
      "| n_updates          | 146           |\n",
      "| policy_entropy     | 1.1074717     |\n",
      "| policy_loss        | 0.0004172637  |\n",
      "| serial_timesteps   | 37376         |\n",
      "| time_elapsed       | 39.2          |\n",
      "| total_timesteps    | 37376         |\n",
      "| value_loss         | 13.904343     |\n",
      "--------------------------------------\n",
      "Episode 330\tAverage Score: -19.42\n",
      "Episode 335\tAverage Score: -19.29-------------------------------------\n",
      "| approxkl           | 0.0011383549 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| ep_len_mean        | 73.4         |\n",
      "| ep_reward_mean     | -21.5        |\n",
      "| explained_variance | 0.691        |\n",
      "| fps                | 1007         |\n",
      "| n_updates          | 147          |\n",
      "| policy_entropy     | 1.0802183    |\n",
      "| policy_loss        | -0.004981494 |\n",
      "| serial_timesteps   | 37632        |\n",
      "| time_elapsed       | 39.4         |\n",
      "| total_timesteps    | 37632        |\n",
      "| value_loss         | 18.481176    |\n",
      "-------------------------------------\n",
      "Episode 340\tAverage Score: -19.36\n",
      "Episode 341\tAverage Score: -19.35--------------------------------------\n",
      "| approxkl           | 0.0035105087  |\n",
      "| clipfrac           | 0.013671875   |\n",
      "| ep_len_mean        | 72.7          |\n",
      "| ep_reward_mean     | -21.3         |\n",
      "| explained_variance | 0.689         |\n",
      "| fps                | 1014          |\n",
      "| n_updates          | 148           |\n",
      "| policy_entropy     | 1.0121796     |\n",
      "| policy_loss        | 0.00037446094 |\n",
      "| serial_timesteps   | 37888         |\n",
      "| time_elapsed       | 39.7          |\n",
      "| total_timesteps    | 37888         |\n",
      "| value_loss         | 16.764578     |\n",
      "--------------------------------------\n",
      "Episode 348\tAverage Score: -19.19--------------------------------------\n",
      "| approxkl           | 0.00020479056 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 72.9          |\n",
      "| ep_reward_mean     | -21.4         |\n",
      "| explained_variance | 0.545         |\n",
      "| fps                | 989           |\n",
      "| n_updates          | 149           |\n",
      "| policy_entropy     | 0.9722659     |\n",
      "| policy_loss        | 1.5033525e-05 |\n",
      "| serial_timesteps   | 38144         |\n",
      "| time_elapsed       | 39.9          |\n",
      "| total_timesteps    | 38144         |\n",
      "| value_loss         | 14.608999     |\n",
      "--------------------------------------\n",
      "Episode 350\tAverage Score: -19.14\n",
      "Episode 355\tAverage Score: -18.40--------------------------------------\n",
      "| approxkl           | 0.00021017471 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 71.8          |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | 0.807         |\n",
      "| fps                | 1006          |\n",
      "| n_updates          | 150           |\n",
      "| policy_entropy     | 0.98356754    |\n",
      "| policy_loss        | 4.1247113e-05 |\n",
      "| serial_timesteps   | 38400         |\n",
      "| time_elapsed       | 40.2          |\n",
      "| total_timesteps    | 38400         |\n",
      "| value_loss         | 13.4312525    |\n",
      "--------------------------------------\n",
      "Episode 360\tAverage Score: -16.73\n",
      "Episode 361\tAverage Score: -16.67--------------------------------------\n",
      "| approxkl           | 0.00083008996 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 71.7          |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | 0.695         |\n",
      "| fps                | 983           |\n",
      "| n_updates          | 151           |\n",
      "| policy_entropy     | 0.9889498     |\n",
      "| policy_loss        | 0.0008198536  |\n",
      "| serial_timesteps   | 38656         |\n",
      "| time_elapsed       | 40.5          |\n",
      "| total_timesteps    | 38656         |\n",
      "| value_loss         | 12.991571     |\n",
      "--------------------------------------\n",
      "Episode 367\tAverage Score: -16.63--------------------------------------\n",
      "| approxkl           | 0.0053485925  |\n",
      "| clipfrac           | 0.034179688   |\n",
      "| ep_len_mean        | 68.2          |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | 0.808         |\n",
      "| fps                | 954           |\n",
      "| n_updates          | 152           |\n",
      "| policy_entropy     | 1.0085158     |\n",
      "| policy_loss        | -0.0057572406 |\n",
      "| serial_timesteps   | 38912         |\n",
      "| time_elapsed       | 40.7          |\n",
      "| total_timesteps    | 38912         |\n",
      "| value_loss         | 10.782357     |\n",
      "--------------------------------------\n",
      "Episode 374\tAverage Score: -16.48-------------------------------------\n",
      "| approxkl           | 0.0039135134 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 60.2         |\n",
      "| ep_reward_mean     | -18.1        |\n",
      "| explained_variance | 0.584        |\n",
      "| fps                | 997          |\n",
      "| n_updates          | 153          |\n",
      "| policy_entropy     | 0.9891692    |\n",
      "| policy_loss        | 0.0028018837 |\n",
      "| serial_timesteps   | 39168        |\n",
      "| time_elapsed       | 41           |\n",
      "| total_timesteps    | 39168        |\n",
      "| value_loss         | 9.393023     |\n",
      "-------------------------------------\n",
      "Episode 377\tAverage Score: -16.50--------------------------------------\n",
      "| approxkl           | 0.0010980344  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 60.1          |\n",
      "| ep_reward_mean     | -18.1         |\n",
      "| explained_variance | 0.464         |\n",
      "| fps                | 1005          |\n",
      "| n_updates          | 154           |\n",
      "| policy_entropy     | 0.9930772     |\n",
      "| policy_loss        | -0.0024351017 |\n",
      "| serial_timesteps   | 39424         |\n",
      "| time_elapsed       | 41.2          |\n",
      "| total_timesteps    | 39424         |\n",
      "| value_loss         | 6.8022375     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.010532355   |\n",
      "| clipfrac           | 0.22558594    |\n",
      "| ep_len_mean        | 60.1          |\n",
      "| ep_reward_mean     | -18.1         |\n",
      "| explained_variance | -0.12         |\n",
      "| fps                | 1047          |\n",
      "| n_updates          | 155           |\n",
      "| policy_entropy     | 1.0233018     |\n",
      "| policy_loss        | -0.0037817955 |\n",
      "| serial_timesteps   | 39680         |\n",
      "| time_elapsed       | 41.5          |\n",
      "| total_timesteps    | 39680         |\n",
      "| value_loss         | 1.4299825     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| approxkl           | 0.0008504832  |\n",
      "| clipfrac           | 0.009765625   |\n",
      "| ep_len_mean        | 60.1          |\n",
      "| ep_reward_mean     | -18.1         |\n",
      "| explained_variance | -0.143        |\n",
      "| fps                | 1100          |\n",
      "| n_updates          | 156           |\n",
      "| policy_entropy     | 1.0415082     |\n",
      "| policy_loss        | 0.00020058767 |\n",
      "| serial_timesteps   | 39936         |\n",
      "| time_elapsed       | 41.7          |\n",
      "| total_timesteps    | 39936         |\n",
      "| value_loss         | 1.1757731     |\n",
      "--------------------------------------\n",
      "Episode 380\tAverage Score: -18.13\n",
      "Episode 383\tAverage Score: -18.30-------------------------------------\n",
      "| approxkl           | 0.0012358578 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 67           |\n",
      "| ep_reward_mean     | -20          |\n",
      "| explained_variance | 0.714        |\n",
      "| fps                | 922          |\n",
      "| n_updates          | 157          |\n",
      "| policy_entropy     | 1.0638433    |\n",
      "| policy_loss        | 0.0029568987 |\n",
      "| serial_timesteps   | 40192        |\n",
      "| time_elapsed       | 42           |\n",
      "| total_timesteps    | 40192        |\n",
      "| value_loss         | 8.244193     |\n",
      "-------------------------------------\n",
      "Episode 389\tAverage Score: -18.24--------------------------------------\n",
      "| approxkl           | 0.00025747562 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 66.9          |\n",
      "| ep_reward_mean     | -19.9         |\n",
      "| explained_variance | 0.835         |\n",
      "| fps                | 899           |\n",
      "| n_updates          | 158           |\n",
      "| policy_entropy     | 1.088681      |\n",
      "| policy_loss        | -0.0014481944 |\n",
      "| serial_timesteps   | 40448         |\n",
      "| time_elapsed       | 42.3          |\n",
      "| total_timesteps    | 40448         |\n",
      "| value_loss         | 8.116688      |\n",
      "--------------------------------------\n",
      "Episode 390\tAverage Score: -18.25\n",
      "Episode 395\tAverage Score: -16.99--------------------------------------\n",
      "| approxkl           | 0.00024245959 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 67.1          |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | 0.879         |\n",
      "| fps                | 992           |\n",
      "| n_updates          | 159           |\n",
      "| policy_entropy     | 1.1132627     |\n",
      "| policy_loss        | -0.0007554623 |\n",
      "| serial_timesteps   | 40704         |\n",
      "| time_elapsed       | 42.5          |\n",
      "| total_timesteps    | 40704         |\n",
      "| value_loss         | 6.5783234     |\n",
      "--------------------------------------\n",
      "Episode 400\tAverage Score: -17.13\n",
      "Episode 401\tAverage Score: -17.16--------------------------------------\n",
      "| approxkl           | 0.00062458013 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 66.8          |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | 0.855         |\n",
      "| fps                | 1049          |\n",
      "| n_updates          | 160           |\n",
      "| policy_entropy     | 1.0991552     |\n",
      "| policy_loss        | 0.001186715   |\n",
      "| serial_timesteps   | 40960         |\n",
      "| time_elapsed       | 42.8          |\n",
      "| total_timesteps    | 40960         |\n",
      "| value_loss         | 8.463355      |\n",
      "--------------------------------------\n",
      "Episode 408\tAverage Score: -15.76--------------------------------------\n",
      "| approxkl           | 0.00020391187 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 67.4          |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | 0.751         |\n",
      "| fps                | 988           |\n",
      "| n_updates          | 161           |\n",
      "| policy_entropy     | 1.0747596     |\n",
      "| policy_loss        | 0.0023018103  |\n",
      "| serial_timesteps   | 41216         |\n",
      "| time_elapsed       | 43            |\n",
      "| total_timesteps    | 41216         |\n",
      "| value_loss         | 7.2137337     |\n",
      "--------------------------------------\n",
      "Episode 410\tAverage Score: -15.79\n",
      "Episode 414\tAverage Score: -15.77--------------------------------------\n",
      "| approxkl           | 0.00084034295 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 62            |\n",
      "| ep_reward_mean     | -18.6         |\n",
      "| explained_variance | 0.852         |\n",
      "| fps                | 1046          |\n",
      "| n_updates          | 162           |\n",
      "| policy_entropy     | 1.0842981     |\n",
      "| policy_loss        | -0.001265034  |\n",
      "| serial_timesteps   | 41472         |\n",
      "| time_elapsed       | 43.3          |\n",
      "| total_timesteps    | 41472         |\n",
      "| value_loss         | 7.019486      |\n",
      "--------------------------------------\n",
      "Episode 420\tAverage Score: -14.50\n",
      "Episode 421\tAverage Score: -14.53---------------------------------------\n",
      "| approxkl           | 0.00022191861  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 56             |\n",
      "| ep_reward_mean     | -17.1          |\n",
      "| explained_variance | 0.862          |\n",
      "| fps                | 1054           |\n",
      "| n_updates          | 163            |\n",
      "| policy_entropy     | 1.0797397      |\n",
      "| policy_loss        | -0.00078063505 |\n",
      "| serial_timesteps   | 41728          |\n",
      "| time_elapsed       | 43.6           |\n",
      "| total_timesteps    | 41728          |\n",
      "| value_loss         | 6.4041595      |\n",
      "---------------------------------------\n",
      "Episode 426\tAverage Score: -14.52-------------------------------------\n",
      "| approxkl           | 0.0003893589 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 56.1         |\n",
      "| ep_reward_mean     | -17.1        |\n",
      "| explained_variance | 0.832        |\n",
      "| fps                | 1046         |\n",
      "| n_updates          | 164          |\n",
      "| policy_entropy     | 1.1032693    |\n",
      "| policy_loss        | -0.001533125 |\n",
      "| serial_timesteps   | 41984        |\n",
      "| time_elapsed       | 43.8         |\n",
      "| total_timesteps    | 41984        |\n",
      "| value_loss         | 4.459756     |\n",
      "-------------------------------------\n",
      "Episode 430\tAverage Score: -14.22\n",
      "Episode 434\tAverage Score: -14.25--------------------------------------\n",
      "| approxkl           | 0.0007622638  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 50.6          |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | 0.88          |\n",
      "| fps                | 1101          |\n",
      "| n_updates          | 165           |\n",
      "| policy_entropy     | 1.0746708     |\n",
      "| policy_loss        | -0.0028905803 |\n",
      "| serial_timesteps   | 42240         |\n",
      "| time_elapsed       | 44            |\n",
      "| total_timesteps    | 42240         |\n",
      "| value_loss         | 3.676227      |\n",
      "--------------------------------------\n",
      "Episode 440\tAverage Score: -14.09\n",
      "Episode 441\tAverage Score: -14.04--------------------------------------\n",
      "| approxkl           | 0.0041276733  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 50            |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | 0.879         |\n",
      "| fps                | 1073          |\n",
      "| n_updates          | 166           |\n",
      "| policy_entropy     | 1.0383251     |\n",
      "| policy_loss        | -0.0029585026 |\n",
      "| serial_timesteps   | 42496         |\n",
      "| time_elapsed       | 44.3          |\n",
      "| total_timesteps    | 42496         |\n",
      "| value_loss         | 5.392993      |\n",
      "--------------------------------------\n",
      "Episode 447\tAverage Score: -14.15--------------------------------------\n",
      "| approxkl           | 0.00011804991 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 50.1          |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | 0.887         |\n",
      "| fps                | 1017          |\n",
      "| n_updates          | 167           |\n",
      "| policy_entropy     | 0.998228      |\n",
      "| policy_loss        | 7.019029e-06  |\n",
      "| serial_timesteps   | 42752         |\n",
      "| time_elapsed       | 44.5          |\n",
      "| total_timesteps    | 42752         |\n",
      "| value_loss         | 4.93889       |\n",
      "--------------------------------------\n",
      "Episode 450\tAverage Score: -14.51\n",
      "Episode 450\tAverage Score: -14.51\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0012805909  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 50            |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | 0.69          |\n",
      "| fps                | 1043          |\n",
      "| n_updates          | 168           |\n",
      "| policy_entropy     | 0.98734426    |\n",
      "| policy_loss        | -0.0026950664 |\n",
      "| serial_timesteps   | 43008         |\n",
      "| time_elapsed       | 44.8          |\n",
      "| total_timesteps    | 43008         |\n",
      "| value_loss         | 3.4507058     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 451\tAverage Score: -14.52--------------------------------------\n",
      "| approxkl           | 0.00044992883 |\n",
      "| clipfrac           | 0.0009765625  |\n",
      "| ep_len_mean        | 52.5          |\n",
      "| ep_reward_mean     | -16           |\n",
      "| explained_variance | 0.664         |\n",
      "| fps                | 1091          |\n",
      "| n_updates          | 169           |\n",
      "| policy_entropy     | 1.0550388     |\n",
      "| policy_loss        | 0.0007481633  |\n",
      "| serial_timesteps   | 43264         |\n",
      "| time_elapsed       | 45            |\n",
      "| total_timesteps    | 43264         |\n",
      "| value_loss         | 3.4287062     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| approxkl           | 0.004687975 |\n",
      "| clipfrac           | 0.061523438 |\n",
      "| ep_len_mean        | 52.5        |\n",
      "| ep_reward_mean     | -16         |\n",
      "| explained_variance | 0.112       |\n",
      "| fps                | 1104        |\n",
      "| n_updates          | 170         |\n",
      "| policy_entropy     | 1.0295928   |\n",
      "| policy_loss        | -0.00865528 |\n",
      "| serial_timesteps   | 43520       |\n",
      "| time_elapsed       | 45.2        |\n",
      "| total_timesteps    | 43520       |\n",
      "| value_loss         | 2.1310024   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.004828439  |\n",
      "| clipfrac           | 0.10449219   |\n",
      "| ep_len_mean        | 52.5         |\n",
      "| ep_reward_mean     | -16          |\n",
      "| explained_variance | 0.000781     |\n",
      "| fps                | 1176         |\n",
      "| n_updates          | 171          |\n",
      "| policy_entropy     | 0.988616     |\n",
      "| policy_loss        | -0.006670085 |\n",
      "| serial_timesteps   | 43776        |\n",
      "| time_elapsed       | 45.5         |\n",
      "| total_timesteps    | 43776        |\n",
      "| value_loss         | 1.7674562    |\n",
      "-------------------------------------\n",
      "Episode 453\tAverage Score: -16.70--------------------------------------\n",
      "| approxkl           | 0.000987537   |\n",
      "| clipfrac           | 0.0107421875  |\n",
      "| ep_len_mean        | 52.5          |\n",
      "| ep_reward_mean     | -16           |\n",
      "| explained_variance | 0.771         |\n",
      "| fps                | 1142          |\n",
      "| n_updates          | 172           |\n",
      "| policy_entropy     | 1.0424008     |\n",
      "| policy_loss        | -0.0022332405 |\n",
      "| serial_timesteps   | 44032         |\n",
      "| time_elapsed       | 45.7          |\n",
      "| total_timesteps    | 44032         |\n",
      "| value_loss         | 1.976618      |\n",
      "--------------------------------------\n",
      "Episode 457\tAverage Score: -16.83--------------------------------------\n",
      "| approxkl           | 0.0012586531  |\n",
      "| clipfrac           | 0.01171875    |\n",
      "| ep_len_mean        | 62.8          |\n",
      "| ep_reward_mean     | -18.5         |\n",
      "| explained_variance | 0.887         |\n",
      "| fps                | 1043          |\n",
      "| n_updates          | 173           |\n",
      "| policy_entropy     | 1.2216268     |\n",
      "| policy_loss        | -0.0054944423 |\n",
      "| serial_timesteps   | 44288         |\n",
      "| time_elapsed       | 45.9          |\n",
      "| total_timesteps    | 44288         |\n",
      "| value_loss         | 2.3732786     |\n",
      "--------------------------------------\n",
      "Episode 460\tAverage Score: -16.93\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00027730217 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 63.6          |\n",
      "| ep_reward_mean     | -18.5         |\n",
      "| explained_variance | 0.754         |\n",
      "| fps                | 980           |\n",
      "| n_updates          | 174           |\n",
      "| policy_entropy     | 1.2993575     |\n",
      "| policy_loss        | -0.0021308437 |\n",
      "| serial_timesteps   | 44544         |\n",
      "| time_elapsed       | 46.2          |\n",
      "| total_timesteps    | 44544         |\n",
      "| value_loss         | 2.422182      |\n",
      "--------------------------------------\n",
      "Episode 464\tAverage Score: -17.24---------------------------------------\n",
      "| approxkl           | 0.00048011827  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 65.1           |\n",
      "| ep_reward_mean     | -18.9          |\n",
      "| explained_variance | 0.784          |\n",
      "| fps                | 955            |\n",
      "| n_updates          | 175            |\n",
      "| policy_entropy     | 1.2691157      |\n",
      "| policy_loss        | -0.00078173075 |\n",
      "| serial_timesteps   | 44800          |\n",
      "| time_elapsed       | 46.4           |\n",
      "| total_timesteps    | 44800          |\n",
      "| value_loss         | 2.4842856      |\n",
      "---------------------------------------\n",
      "Episode 469\tAverage Score: -17.23--------------------------------------\n",
      "| approxkl           | 0.00034778073 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 65.7          |\n",
      "| ep_reward_mean     | -18.9         |\n",
      "| explained_variance | 0.725         |\n",
      "| fps                | 1046          |\n",
      "| n_updates          | 176           |\n",
      "| policy_entropy     | 1.2476704     |\n",
      "| policy_loss        | -0.003428598  |\n",
      "| serial_timesteps   | 45056         |\n",
      "| time_elapsed       | 46.7          |\n",
      "| total_timesteps    | 45056         |\n",
      "| value_loss         | 3.8376155     |\n",
      "--------------------------------------\n",
      "Episode 470\tAverage Score: -17.33\n",
      "Episode 472\tAverage Score: -17.73--------------------------------------\n",
      "| approxkl           | 0.0016374389  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 67.8          |\n",
      "| ep_reward_mean     | -19.4         |\n",
      "| explained_variance | 0.843         |\n",
      "| fps                | 1034          |\n",
      "| n_updates          | 177           |\n",
      "| policy_entropy     | 1.2976265     |\n",
      "| policy_loss        | -0.0016880914 |\n",
      "| serial_timesteps   | 45312         |\n",
      "| time_elapsed       | 46.9          |\n",
      "| total_timesteps    | 45312         |\n",
      "| value_loss         | 2.1837027     |\n",
      "--------------------------------------\n",
      "Episode 475\tAverage Score: -17.89--------------------------------------\n",
      "| approxkl           | 0.0015406861  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 68.5          |\n",
      "| ep_reward_mean     | -19.6         |\n",
      "| explained_variance | 0.831         |\n",
      "| fps                | 1052          |\n",
      "| n_updates          | 178           |\n",
      "| policy_entropy     | 1.2822902     |\n",
      "| policy_loss        | -0.0027182621 |\n",
      "| serial_timesteps   | 45568         |\n",
      "| time_elapsed       | 47.2          |\n",
      "| total_timesteps    | 45568         |\n",
      "| value_loss         | 1.9366598     |\n",
      "--------------------------------------\n",
      "Episode 479\tAverage Score: -16.55--------------------------------------\n",
      "| approxkl           | 0.0014906083  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 70.2          |\n",
      "| ep_reward_mean     | -19.9         |\n",
      "| explained_variance | 0.77          |\n",
      "| fps                | 1042          |\n",
      "| n_updates          | 179           |\n",
      "| policy_entropy     | 1.2664205     |\n",
      "| policy_loss        | -0.0027748074 |\n",
      "| serial_timesteps   | 45824         |\n",
      "| time_elapsed       | 47.4          |\n",
      "| total_timesteps    | 45824         |\n",
      "| value_loss         | 2.1233742     |\n",
      "--------------------------------------\n",
      "Episode 480\tAverage Score: -16.70\n",
      "Episode 484\tAverage Score: -16.71--------------------------------------\n",
      "| approxkl           | 0.00044027457 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 71.3          |\n",
      "| ep_reward_mean     | -20.3         |\n",
      "| explained_variance | 0.71          |\n",
      "| fps                | 1059          |\n",
      "| n_updates          | 180           |\n",
      "| policy_entropy     | 1.2367017     |\n",
      "| policy_loss        | -0.0018436108 |\n",
      "| serial_timesteps   | 46080         |\n",
      "| time_elapsed       | 47.7          |\n",
      "| total_timesteps    | 46080         |\n",
      "| value_loss         | 5.203511      |\n",
      "--------------------------------------\n",
      "Episode 489\tAverage Score: -16.79--------------------------------------\n",
      "| approxkl           | 0.00065584236 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 71.4          |\n",
      "| ep_reward_mean     | -20.3         |\n",
      "| explained_variance | 0.86          |\n",
      "| fps                | 998           |\n",
      "| n_updates          | 181           |\n",
      "| policy_entropy     | 1.207616      |\n",
      "| policy_loss        | -0.0033163805 |\n",
      "| serial_timesteps   | 46336         |\n",
      "| time_elapsed       | 47.9          |\n",
      "| total_timesteps    | 46336         |\n",
      "| value_loss         | 1.9574248     |\n",
      "--------------------------------------\n",
      "Episode 490\tAverage Score: -16.79\n",
      "Episode 494\tAverage Score: -16.81-------------------------------------\n",
      "| approxkl           | 0.0024644858 |\n",
      "| clipfrac           | 0.022460938  |\n",
      "| ep_len_mean        | 64.2         |\n",
      "| ep_reward_mean     | -18.4        |\n",
      "| explained_variance | 0.938        |\n",
      "| fps                | 1018         |\n",
      "| n_updates          | 182          |\n",
      "| policy_entropy     | 1.1727165    |\n",
      "| policy_loss        | -0.008933971 |\n",
      "| serial_timesteps   | 46592        |\n",
      "| time_elapsed       | 48.2         |\n",
      "| total_timesteps    | 46592        |\n",
      "| value_loss         | 1.2088029    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 499\tAverage Score: -17.00--------------------------------------\n",
      "| approxkl           | 0.0011293176  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 65            |\n",
      "| ep_reward_mean     | -18.6         |\n",
      "| explained_variance | 0.86          |\n",
      "| fps                | 1024          |\n",
      "| n_updates          | 183           |\n",
      "| policy_entropy     | 1.1464659     |\n",
      "| policy_loss        | -0.0043132864 |\n",
      "| serial_timesteps   | 46848         |\n",
      "| time_elapsed       | 48.4          |\n",
      "| total_timesteps    | 46848         |\n",
      "| value_loss         | 1.771605      |\n",
      "--------------------------------------\n",
      "Episode 500\tAverage Score: -17.05\n",
      "Episode 501\tAverage Score: -17.06"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7f0894e8c7b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create log dir\n",
    "log_dir = \"/tmp/gym/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(1e100), callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"dqn_\")\n",
    "model.save(\"ppo2_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'episode return')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3gc1bn48e87u+rFkm3Zli03bGPcwQ0DBgzY2BiIIRBiSqgJCeHe9HApCZAQfknIBXIhlJgaQoghEEroNUCwAReMG+69yZIlq7fdPb8/ZlZaSbvSqKx2Jb+f59lHq7OzO2d2Z+adU+YcMcaglFJKuWHFOgNKKaW6Dw0aSimlXNOgoZRSyjUNGkoppVzToKGUUso1b6wzEG19+/Y1w4YNi3U2lFKqW1mxYkWhMSanaXqPDxrDhg1j+fLlsc6GUkp1KyKyM1y6Vk8ppZRyTYOGUkop1zRoKKWUck2DhlJKKdc0aCillHKt2wUNEZknIhtFZIuI3Bjr/Cil1JGkWwUNEfEADwBnAWOBi0VkbGxzpZRSR45uFTSA6cAWY8w2Y0wtsBhYEI0VPfnJdv7v3c0s3XqIz7cXsSm/DIBPtx2qf96STfllLN16qE3rfHnVXoorapulHyyt5s21B+qXKamqc/2ZL36xp03L7ztcxdvrDrS6XFWtn+dX7MHN0Pq7iyr5YMNB13kAKK/x8Y/lu119flNvrTvA/pKqsK8FAobnlu2mxudv02cerqzllS/3tbqcP2B4dtku6vyBRumfbjvExgOR95t/fbmPwvKaNuUp6GBZNa+v2R/2tU+2FLK1oLxNn2eM4YUVeyipdL/fhNp3uIp31ue3ulxb9qFIdhdV8v6G/Prnb67dz4tf7OG55bs5VF7DS1/s5fkVe3hjzX7eXNvweOmLvfxj+e769DfW7OfjzQVh1/Hm2sj7UyTLdhSxfl9pxNffXLufgrLGv/eWg+Us2VIYdvmiilpeWx3+N+5q3e3mvkHA7pD/9wDHN11IRK4FrgUYMmRIu1b09Ge72HKw8cG243dns3DRp/XPW3LmvR+5Wi5o7+Eqfrh4FSeP6stfr2m8Sdc/s5JlO4p560en8MPFqzh+eG+e/e4JrX7mV/tL+fGzX3LupIHcf/FxrvJx4UNL2FdSzcbfzCPJ64m43P3vb+bBf28lI9nL3HEDWvzMr/3pPxRX1rH9t/MREVf5uP2VdTy/Yg8j+qUzeUi2q/eAfSL67l9XcFTfNN7/2axmr3+0uYAbXljNVwdKue3cca4/95aX1vLa6v2M7p/B6AEZEZd7c+0B/ueFNewpruKnZ46uT29pvzlQUs1///0LTjiqD3+/dobrPAV9+y/LWb2nhFW3ziErNbHRa5c++lnE9Uaybl8pP/3Hlyw4diD/t9DdfhNq4aJP2VVU2eo+9MAHW/jTB1tIT/Iwb3xum9cDMP++jymr9rH1/83njLs/pLZJsG6rpt9TRY2P7z29gqNy0nj/p7Ncf843Hl4a9vMAanx+vvf0ymafOfueDyO+5wd//4L/bCnkuCGnMzArxXU+oqG7lTTCnXGaXaYYYxYZY6YaY6bm5DS7C77dK2qPQMDdVVTwqmNzfvOrwrJqH2BfSQGs3FXs6jPzS6sB2H/Y/VXSvhL7PfklLV/11vjsg3NHYUWrn1nsXLGW1fhc5yMYsPcfrnb9HoBdzne0LUK+giexVbsPt+lzg79B8PMjSUm0D6kVO939RtCwrZsPtl6CDWf1nhJXeXNr7V778/YWt+3qOiiYj9beH3BKGBtaKIG1Jvi77C+p6nDACGdbQUWjv53B75wTIn1muNqG4PnhcDtLf52puwWNPcDgkP/zgNbrDDqJ22K0L2TnLapsvgOEc8A5WTet1gDIy04F4PFPtjvLuMvHHuegTUpo+8+853DLJ6B+GUkAHCxzX6VSVG5/F9sLKyhvJYAEv4cdhyogfx188TSBop1hq5X2Hq7iky2FlFTW2cu3wOuxLwd2HWq8fat2H2bFzqJGact3FFFSWUetL0BuZjLQELirav3U+QP8ZckOthdWsHJXMbW+AF7L/q6XbD1Uf3II5Wvy+xZX1LJ6rx3ARITKnSso+/AB2PQW1NrrMsaE/aymdhaWQ3kBBJrvQy3tu4fKa3jsP9upqvXb1SBOVVdezWbMS9fB81fDlnfB+Qx/wPD0pzvrq4WCn1/j81MR8rvuPFTJ4s93sSm/LOx+Hbxi3l1UVf+5uw5Vhs3rgZJq1uwpYXdRJXe9uYGPNxdgAgGC14ybduwmg84JmqG2FYZcxB3aChteg8qG/aSkso4bX1hdf4HWVK2v+XZH+i3Tk7zN1+lIS7Ivdipr3V94RUt3q55aBowSkeHAXmAhcEk0VhSuFqWiNnw9+IebCnjggy389ZrpPPjBVo4dnFX/Wtm6t+lbvAT6jmL74PNIS0nltTX7mTtuQKNiZnCnq/MH4PBuOLyTZ3b2osqTTmaK/TMtCWkj2VFYgQgM7ZNWn7bvcBUZyV4ykhOorPVx7zubALACPt76+/0EKg9x1gXX4M/Mo84fYPmOYj7ddoiF0wczsFdK/QnXi483Hr+DkSlv0StwGN+AyVQOPoU+Y2dRnDqU/bWp9XXWB8tq2Hu4ihtfWM2avSX0SYK7Tk1gR1Uqq0vTuDWkCmjV7sP8+aNtPLd8N33SErl4cBET8l+GhBR6DTqG7NxhZKSlk18F6Ye2cZpVxMR//wE+/AKAgHh51H8uWZMv4JQ8D2lV+/hsv59HvqgkW8o4NXEDJ5kvWJNUjGAI3OnBJ15erxrH255ZmF55HC7YSwojOFQBP3l2FR5LuGTaIB567M8U+lLBm8TZWbs5PW0bO/eW824gjwLpzbAsL9Mki1+/ChsPlPHO2t3Mr3uHUbKHFW/UkEo1pdTQNz2RKTKfFWY00+58l8xkL+fkVTFS9rDF5PH2+nxe/GIvF00dzBnH9OPkuz6gvMZHOpX8qOoxUp94r/77CnhT2NPvVBYVTmJNTX++OaSUcf4NJNccxCT3ZktNL74qgu95KhhvbeeMVzeAr4R8+rB79JX4pn+//rOKK+vonZZIZa2Pe97eRG5WCnuLqyjO3w17lzOibiPbl+bjrcznu/40vpdgOOnwOsq+SMFKTCFt7Qtsz5zKu/4pJKdlsn5vETukmqQBdfSqy8dXVcbWqlQOmV78xltNtpSR/LdyjpUysqSMMq+X2rRcarNGsNkawWZ/Lgm9+gFeXli5h3fWH6C02sdCz/t8O/l9rPT+bPXnUJc5jDVFQnlZCQOkiAFSxEkUM2BJEdVWMTuSq6k2CSS/XMdriTmcUXs3dR04rRlj2FZYgSWC1xJW7T5MNqX80PtPAve/g4XBJGfxVN6v+aBuDKmJHr5a+wUPrHyUiUkHyU2uJTM7h7lWLm8HpnD63f/mqEzDzMMvM9azlz45/cgeOIokhlNDIgsXLeXKE4eTnuStDzBbDpaTmZzAmr0l5JfWMCmvF2lOQAm92Ppy92Ee/nArCR6Le+Zk4S3eAr4aSOsL/cdBUuRq1I6Q7jZHuIjMB/4IeIDHjTF3trT81KlTTXsGLJx770dsbNLgveTG0znxd+8D8NWv55GSaEf/a59aztuNGv4M02Qj13pfZY5nJX7x4jE+vgoM4fe+heTKIS7I+Ip0Tx2BvOO5a/twPi/NZqzs4ErvW5zjseuh64yHTwNjOEQmj/jOZp0Z3ig/CR7hvZ/M4qVnH+GiY5I4/e0cRg0ewB0LxrFw0adU1vrJpJwnU+9ncmCNnTOxWJo0k0Wlx1Nq0hhr7eRcz1JGyR4qSabIZNJHShgkh/g8MJpNDGUKGxhj7apfb77JYq/pyz/8p/J3/xn0TU+isLyGi5I+5Zc8QobYV46v+adTO+ly/rNyLRlSyV7Tl3WBYZzSu4i5Ff/iNFlBpUlCMKRI+BJZsfTi0dq5/DswiW97X+d8zycRf7M6vCzxj2WLGYQBDEIW5ZzpWU4vabgKXRUYwQW1t+PH/v1u9T7F1d43G33WftMbwTBAGlczveqfwQf+Y/lB0qsMNXs4bNIoJ4VKk0QlSeRKEcnUcmnmE/i9aXy1v4TVSd8hUyo5q+a37E4cUX/gJydYJNWV8gvv08xLWEmqqeS11PN4LuFrULCR+d7lzJVP6SMN+2GlSWK/6U22lNFbGq5ID5hsPgmMZ31gCKdZq5jpWccNdd/hOf9pANz9jUl8vr2IlbuKKTy4j3M9S7nA8zGTrG0A+PCwOTCI/aY3k3MMSdSx6OBoHvPNp4okLvW8y/Xel8mRkkbfR6VJYq/pSwXJ9JUS+lBKBckUmwyKyKDYZFBs0vHiZ6Ac4mhrT6PPuKPuUh7zn80xAzIoO7CNj5N+xC7Tj3JSGCL5ZEpDFVed8ZBPNql98thYmcH68nTKSSGZGpKo40rv2/yo9vu8FJgZcR9pzTUzh/PYf7bX/3+W9Rn3Jj1MoqnlL74zOZR3BhcVPkhu3W7eCExnhOxjnGWP61dqUjls0ugtZaRLNesCQ1keOJoFnqVkSTn7TW/SqCJTqnjCN5df+a6oX89E2UqaVLM0MI7JQ7JYv7+U6roA13he5yrvm5SZVK6p/Rkjjx7Dt2YMZdFHW1m2o4iTrLV83/MKJ3nWNd4QbwpMuADm3AGpvdv1XYjICmPM1Gbp3S1otFV7g8a8P37UrK71zR+dzLw/flz//6TBWXx75nBueH41VXV2KWSoHOBPCfcxwdpBqUnlAd8CHvefxSnWl/wu4RFyxO5Rscf0pcykMlp2Y0nDb1BqUvirfw7rvGNZkLWNsRXLGFy3nQLTixNq7sfX5CrqKNnHG4k3kiQ+AkY4TBrpUk2hyaTYk8PAwH7STAW3+K7hs8AYLvG8z2Wed0iXhuL0psAglgWOIVlqOWmAYWtxHY9Vnsz7geP4+IbT+f2bG/hs9XrGWzs4xrufkWYn42U7o609XFZ7E/8JTOBbY4Rf7b6ajWYID1SdyTHWLq5JeIcUE77KwCRn8XDNXB6smsOz/z2HioJdVBbvo6C4jIHpMK5/Mr0yMmDwDL711Jd8vLmQYX1SeeGCXuzctJoSMvi0KJVpA7yckWeQ5EzMgAms3F/LwdJqHvz3VgLG0C8jibW7Cvjv4XtJM5Uc3Lyc67z/YvnMR9iQfjxjchIZ9dRk1gaGMfbrN5DmhY3WCM5/ZjeXnzCcX87O4zfPfcgb6w9xTeZnXO57Hm+gFpM9jDUTbmZVyvFcMDmPJK/F/e9v4T/vv8oLSb9i/6z/JXfWd7j45rv4e6J9XfOg72vc5VvY6HtYnHk/x9ctg/FfR2ZcB4MmA/CXJTu47ZV1XDljEL+cWIanfD+B3qMozx7Nij3l7Cmu4rLJOazetpeD1R4kIZVFH28nJyOJ19fs5YXE28mhhFm199QHxyQP/CTpZa4JvIAXHwXpo8mafjEJw07E1288D/xnH75AgJ/MORoRYcnWQgZnp3KwrIaiilqGZKdQU5rPayt3MHv8QMYMGUBqejYfbCqgstbPnLH9eXX1fn72jy8BePTyqUzM60VORhK/+td6Kmt9lFfXceqAOmoLtpK3fhFTrE3U/HA9vbOyOfzGHfRZdjdvzXmb13Yl4hX49Zm5JPgrSUpOo8ybxaaDlUwZaneMePTjbVgizB7Tn2ufWsbiwxfzqn8Gv/Bd4+YQDysz2Uup005yzjGZ/GHPpSTlDMc6/2HuWil25w8q+evAfzK89DNqMoeTOelcDuTNpcDqR1mNj28/+TnnWEu5Me1Vcv37kJFnUHL8T3nn8ED+/OFWvlN0Nws8S5hY8wjXnj6WZdsP8ei+80mXai6uvYWlAbt0/uDMauYvv5o1gWGMlZ0855/FTb7vACAE+FPKIs42H3HQZLMi95ucNf98SEiBsgN2Ndr2D+H6ZeBNjLi9LYkUNLpb9VRMlVY1rk9cs7sI3/N38jfJ53p+yGhrN4tSH8Lr9WLm3MdjBybywaZS6vLLOX7epaRP/iHsX8b/La/g3i89gDAyrZrHTyqm5OAu9nsG8uMVfakghR2/sXtQ/NczK6le+yqPJt7NCdZ6Pg5M5J6LJjFnbH/m3/cx80qWkSQ+vl37UyZY2+lDCeWkcNZwD2M9hyioG8p/HTqT4ZNm8p3sVH75Un/+5D+Ptd8bBLXlPLouwLZALrd9bRyfbSui38i+DLCEcZW1+AOGPulJ/OmSyRQvGM/G/DJmHNWHBz7Yws1vreH1xJt4qv9iSq+8jl6vX4eI8HDfX/DqDg99Z1yMddo93PLQU3xWnEaRyWSYHOC26QEmjRuPDD+V8yoNkworGDsoCwZlARPDfu8/nnM0pVV1PHnVdLLTEulzlH1iPa3JcgJMGWpX1501oXlvnJe+2Mu9Xw3jYs/7HHXgDaZedhFseB2kkoFn/w9Zx50HwHhg7a/G1Teae3JGsheLF9Iv4eqrbofSvciAiUz0eBvluG96IivM0WwN5DJww2KY9R3uP3o1JdtT2Wn6c6K1FoBJeb34ck8Jf5pZy4zlS+G0X8CpP2+U18tPGMrxR/Xm6H4ZWJZdV2oBmcBpo1Prl5t0zKj657OdXmzz/ljOgwcX8Gji3ZxjLeVl58r77dGvMnTbszDhG3DSj8gZML7+vV7gh7MbPgvgxBF9ARjcu2F95GYycXTj5c4Y07/++cmj7Pc8cvlUZo9tSL/9a417qt3zTh9e9uXzfNKvqdr8Mp5pV9Bn8/Mw/BTmnnQ8c0+imQxgytCk+v+/ffJR9c97pyexsXgwo63dzd/YBqXVPs6ekMuIfun8ZPBmWFwCc34F/cbw87mGz7YXsWIneC94mF6DetW/b5jzALs0/0rgJE6Z930unJIHQC/gQmB0/wzufXAaF3k/ZLK1mW/NOIufTqyFh+2LuJnWmvqgMV+WQEIafxv5CNPW/pqzPZ9xu+8Kakjk2VmlTP/0Izj5p7zi+QaD+mTBEGefz50ER8+FgB+syL3X2kuDRhuUNrnfYZa1qr665N9JPyFJ6qDPBFj4N8geyo+BBdPLueH51ZwzcSAp6SkwajaXD6xl2JgCzp6QiyVSf1KYAPxxXD65vZLr1+G1hI8DE6gwScyxVvBxYCKWCBnJCXx8w+kUPr6IusNDefQntxIIGI66+XUArrx8HpLgoR+wKCTPtb4A4wdmwtA+AHw75Pg/5eiGnmZNu25mpyUy4yj7PYkeixoS+YXvav5efCdZf50DhRth9u3UbB8EHCAnI4mkjL6kjJ3HFqe4X2Qy6X3qaeCchHJ7QW6v1rsPTh6Szcv/1f4qhyCPJdSSwHuBySzY/R74fbD2BUjJZti0xt0cQ7uKZjvfhQiQ0d9+hJHgsQBhsf80bjnwDOxcQt/db/GE/zRKSOO/PS+SSQUXTh3P908byZkrvw9p/eCE7zf7LBHhmAGZ7drOJK/Fe4Hj2BjI4/veV3il9kQmy2aGbnsGpn8Xzvp9+Ea7TtA/M9lV994ES1huRrMxkMeoL56EfiPh8E447ZZ2rdcSYVMgjwWeJdiN4+3fvh/PGcXIfhnw6sOQkAZDTgTs3+SJq6bx8aZCxocEjKYSPRY1vgDpSc1P2JYFywLH4DfCzWMK6ZeZDGs+AOwq0VOSt3P4uOEM75sOy26HoSciCcm84j+RCzwfc4K1jtlf+xbTd90KqX1h1k1825MQ4Uvp/IAB3a/3VJcJdz9BkdMV7smrpgEw3dpAjfHyi/4PUD766xye9iO45i3IHlr/nqNy0nn+uhMbNXpnpyWy4NhBeD1WfcAImjO2f6Md0mPZJ+jPAmM4yblSDc1a37INJAyaBIBlCY9ePpV7LppEckL4HeaamcM53jn5t1eC0wNpaWCcfRIq3AhDZ8KM6zFOb5Ycp3fVhDx7Wy6cksfHN5zW+Kq1iwXz/Z7/OLw1JbD1Pdj4BoxdAJEOPCArxX4tXE+YUF6PfTj9038yxvLCE2eBv5bnzBks8Y/DI4bp1gaSvRZzR6Qg2z+EYy+GxLQWP7etEr0WBosHfAsYbe1hvvU5v0l4HJOZB2fcGrWA0RZeJ8A+7Z+NdWAVvPR9SMqEMee26/NEYIsZRKZU0pfIN9W5kZns7Av7voC8qY2qdzKTEzh7Ysv3lCR57f0g2HgdymtZlJHKGjOc3KLP7cTdn7HfyuVN/zRG+TZxy7xRXDI+FQo3wbCZeC2LJYFxlJoU5lrLuezYLHu/Hf/1FvfbaNGgEUG4w+qGF1YDMCkvi/6ZSUyxNrHWDKc2ZwJ9LllE1tm/6vQTgHMe4pPAeEZY+xlEAVbwoK+tgOLtMGBC/fKzx/bn65PzOjUPTSWG3rA1/y742Wa44hXwJhLsTRjsPnj2hFx+Pnc0t8wfE9OAAXYABng/cBz+xAx45iKoq4DxF7T4vmCpq7WgEQxKh+hF1Zhv2InjL2SbDGGVGUmVSeQkay2JXgu2vAcBHxx9Vge3qrlE56T1WmAG2wP9eSDxPsZYu5Gzfg9J6Z2+vvYIflcv+WdivClQsgumXQOJ7dtHLBEOGLuto7+4v0cmHI8ldvfiQ1ug79Ftfn/w+AgXNILH89LAOHofXmMfw7s/Z2PiGFYGRpFMDeSvhb0r7QXzpuKxhDq8/DtwLGclrIS1/wR/DUy4qN3b2BEaNCKIdDE2IieN7LREhvdOYazsZHXgKBYcOyhq+Qie6N4N2PX4cz3LG4JGkd3zhT4jo7b+cIInpXrp/eqLwgOc+xkyku0DxuuxuP60kWSnta8xrjN5nVJdNUmUjb/cTuw/AYaGqUAPkZXqrqSR4Gn4Xirm3gtXvgbnPVhfLbYsMJoTrPX2leimNyGlNwye3oEtCi/RyYcfDz+tu46yrDF2tc8x7u8Kj7bgb1FGKvLdD+Gsu+y2nXayBPKN3UuovxS1snRrebOg/CDUlELfUa2/oYlgSSM9bNCwX1saGItlfLDiSag4yFeJE1gRcALU7s9h30pAIHdSfYD9yHM8WaYEXv0R9Btrl4JiQNs02ujS4+2qpwfP7UfaIzVceu5cEkf2jdr6ggfXTjOAdYGhzPd8RkEwoB3aYv/t4qAR3InDuWn+MYwdmMnMKH4n7eUJqQosPfFmskZMswNGK3W/9UGjlTuOvSGfn+D1wDC7HcbjBPklgXHcmLCYQ3WFsPltGDU3KvXOoUF9pTmaL89+lZmj4uv38IYEWHJG248O8FhCfmeVNDwC+fY9Th0JGlaYK8/gvrA8MJqAeLHeuQ2ANclT2IeHIqsPvXd/DpWFdmBIyqgPNMsST4De78GBNXDq/8SsmlFLGhFE+j2CJ57eFXbjbuKA6A6yG3qie91/PFOtTSRXO4P/1QeNEVHNQ1NJTUsaIVITvVw8fYjrMaa6UuhJ3eP1wLjz7VJSK4IN4TVtKGmE/m4eT0PQABi+4c9QVWz3cImC0HxA+0YEiLaWLjzaQ0QooBcBI83urWkrryVQssf+J2toywuH8fsLJzJlaDaDezfv5OGc/+17onKmQ6AOcidxOKE/IGxKHAs7/gO7PoPhJwMN31XAmwhXvAo/WAXjzmvXtnWG+Nub4oRE6H1RfzIo2GD/7eAVUmtCTz5vBuwG+P77P3DysBEy8zq9HaU1zaqnuonQq1uv5f6k1ctpCA/eHxD580NKGiHrCl5xrjPDKDWpDNz4V7ASYOQZrvPQFk1/n5aCfKwEh1vpLJaADy+HyKQ/Haue8lgC5c5IzxktD8YZzrRhvXnhuhPDDtYYut3rptwBx5wD5z1cf5xvThpvr9tXBUfNasgPzn6UkgW9hzf92C4Vf3tTnGitpEHxdkjJbvfdlm6Fnty2moEcMNn0LrDvGOfAWgjpa99Vml7JdheNrv7bEDSSEzy89oOZ/OmSyS0uF6mkEeTHw2t+ZwTjKVdCcuRumx3RNEi0NNJsrHg7uaQRDMwFJou+Te5abyuPiH2DXGJGp1+QhcbK2ozBdvf8/mPr8/9xxjzofZTdG3GUXRIN7lfxch+2tmlEEGmXbggaOyF7WNTz0fjkIywNjOXsg59BXbXdJS8GjZuJ3TRohAbgtpQ0AMYNbP0EH1rlEvr5oWv6he9qZs6/hMFTz2nT+tui6e8TjyWNzr7wCJ50D5mMRsOutOuzLCdotKOU0ZrQkkboVxDcXWo9qXDdErC89RGmLRc4XSH+9qY4F2zIonhHu+o727w+Z4cJnoSWBMaRWHMIVi8G44fc8HdRR1N3rZ4KPfia3h/TGUJPCJHadPx4qB01v91dS93wWPHfptHWoN2a4O9ZRCa9O3ifBgDl+VEJGp6Q/SK0oTy4b3pE7KFAQu6/CH5XpvksEDERf3tTvIhw0Hs9Yt+ef3hXl5Y0gn+XBpyG99d/bl+NDD816nloqrtWT3kjlAQ6i9vvpauv/OOxeqrzSxr230Mmk94dLGkAULYf0sPf+d8RofG80UWMc74JdzETb8dbfOUmjkQ6pVgi9g4VqOuSoOENbQQD9ph+lGePBX8tjDjDbhjrYvFY3eFG46qBaAQNd5/Z1SW1ePy9otWmcchkkiFVJOFuHpuwjIGy6JQ0Iu2DDY3dzd8TfC1e2jTib2+KE5Eawr2W2FVT0Gi4kGixwuxMm0+6ByZfDgseiPr6w+mu1VON2zQ6fxu8bksanq698o/H36uzv//6+12x55DoTQdKGzWldu+lKASNRiWN0KqqJjUKoTq7e3JHaUN4G3kaBY1hUV9f05IGQHX20TD1/qivO5J4Ky671bg6oPM/P1KVV9MLkK46id901jEsnD4kLn+vzj4RBo+PImMP8thbStlv2jnGWpkzN056F5Y0pPlx3rBcfPWeir+9KU602HuqeCeIBb0GR1iq89Q3aoZkKNadKeLxytWN0CqRaNx86PZ76arvz2NJ/T0m8cZtqcythjYNu6TRRzrQGF5mT3cblZJG6HEcpnqqO5Q0uufR3wUinVTsoLHdvqmuC0aYDO4vVpiibKzE45WrG9Huuhi5cb1xerx1oYyFzu6IEPxOD2F3je5Q9VS5U9KIQtAIPa+E60kVvqQRX/tL9zz6u0CLJY3CzdC3a8Z78niC49g0pMV6H4rHhlU3EqLQjhGqs6+ee7LOvvCQkPs0APp05Aa/Mudu8Cj0ngrVuCHc/hsuaASrtAJxUj+le3kEEe8IF5yg0cPVgAMAACAASURBVPYhk9sjeEUWeoUS63Gdum1JI8rF/O5602MsdH7vKftvKWnUGU/HbvArO2BPvpSU0TmZi8AKU9IItwtFo3t4R+he3kYpVfn2HAztGP2yPRoayBrSwl2NdKV4Ky67Fe2Dr7NPhO0VLzeBtaSzS30Nx4RQTEbHbvArP2DPzhjl4yzczaZhSxoe7XLbLUQasDCt3B7dlj5dFDTC7Ezd9Jwdc7Fr0+haJzgzM07M6/p7eNyK1n0a0AlDiZTlR6XnVFOeMN1vu8PNfdrlNpII+3RSxV77SRd0t4WGgytcUTaWUhI8XHHisFhno02icW9GqEjVhsHkK08cxoQW5pbuLGeOG8CqW+c0m+c9nnR20Aj96u27wjtY0hgQ/eF5Ig4j0kT9zX1xUoLUoBFBpF06pXwviAcyozdbXygrTPVUHMQMvrpjXqyz0GaxrlY7YUQf5o6L/hUsENcBAzq/eir0ZFtEJhPY1v4PKzsAo87shFy1LPQiJtxxHqRdbru5xIo9kDkQPF0Tb8M1hMdDSUO5F/y1wl1FHqk6vXrKCq2eymz3fRqpVENtedR7TkHTcaiCaXpzX1gi8g0RWSciARGZ2uS1m0Rki4hsFJG5IelTRGSN89p9EuUuRDOr3uc064tm6YnleyFrSDRX3YinPmg0pGnQ6J5iXdKJJ53f5bbheZHJIFOqSKSuzZ+TK4fsJ5kDOylnkYVrCA93YREvbWVBsSpprAW+DnwUmigiY4GFwDhgHvCgiAQH6nkIuBYY5TyiWj+yoPwfLPR80Cw9oXxfl1VNgTaE9yQaNBp0+tDoTaqnALLbcYPfwGDQ6JXXKflqSWiA8NR3uW2h91TUc+ROTIKGMeYrY8zGMC8tABYbY2qMMduBLcB0EckFMo0xS40xBngKiOokuWVWJtlhemB4qosgLSeaq268vjAljVjfp6HaR4NGg87+LkI/rtAZf6o9VVQNQSP6QwSFG0Yk3LHt1eqpFg0Cdof8v8dJG+Q8b5oelohcKyLLRWR5QUFBuzJS5slsNhRBErVYdRVRn+I1VHCH0ZJG96fVig06+8KnUUmjftDCMrz4mGWtstsqXBgohfa4chm5nZq/cEJLGlJf0mi+3BFTPSUi74rI2jCPBS29LUyaaSE9LGPMImPMVGPM1Jyc9pUKyqxezUoaWZTbT1LbOXpmO9SPV6htGt3GiJzG80oHfy4taURP4+opZygRSvit91GeTLyLm71/c/U5eVIIGV3T0aVRSaOFY7qh00B8FDWi9s0YY2a34217gNByYR6wz0nPC5MeNeVWL7IoxyJAwImt9TOCdWHQCF/S0JNPvNpwx7yIv0+c3aMVF2aN7pyq3tDvvNDY98IcY+1mgecTAL7h+ZDf+y6mjJan2R0mB7rsHiy3Q/XH28198ZUbeAVYKCJJIjIcu8H7c2PMfqBMRGY4vaYuB16OZkbKPZl4xJBJRX1adgyCRrgZvTRmxK/kBE+zoc+DowtosG9s7a/m8sjlU1tf0IXQ46OENPJNFtd5/0Wi+Lmt7gqSxMd066sWP0MIMFp2Q/9xnZKn1jSunoq8XHC/OaLbNETkfBHZA5wAvCYibwEYY9YBzwHrgTeB640xfudt1wGPYjeObwXeiGYeyyxniOWQKqr6No4YBI3QYU1iPTS6ap9o35He3aQneTvtKrrxMSGsDhwFwO5ADov9p1FtEjjJWtfiZwySQtKlusuCRrjdIVxgiLdrjZjcEW6MeRF4McJrdwJ3hklfDoyPctbqlXmcxjRK2YbdZzsWJY1wjWAaM7onjRnR0/TE+mlgDHM8K3nGfwY1JLIsMJoTWwkax8kW+8mArjnNhF5EtNQxIFjSSE7o2mmCI9FhRCKotOygkSFV9e1PmVTaT5KjP35QULgqDa3m6J60ITx6mh4Tf/HP5d+BY9lq7E6WSwPjuCHhWfpSQiHhj9+5nuUUmExyco+Nen7B/cVf77REfj53NPMnRL9Hlxt67RNBjZUCQAZV9WkZUoXxJoO368b1CV6MhA5WpjGjY/KyU2KyXh1GJHqafrc+vPUBA+DDwCQA5nqWhX1/LoeYY63gTf90sLrmir4t3Y6vP20kw/umtb5gF9CgEUG1ZfeySJeGoJFOJSSmxypL9bSk0X6bfnMWH/xsVpeuM/hzaVtU9LR2SKwzQ9kUGMQ3PR8QruvqFd63EAI87Ds3OhnsQTRoRFBl2VE9PVglhRNAojyblxsaNNov0WvFrAujljSip/VjQnjUP5+J1nZObzamnGGutYwlgfHspetGe+iuNGhEUCvJBIyQJg13kqZRjXRx0Aj2mgrtVaEXrN2TtmlEj5uv9gX/KZSalGZBI5cihlv5fBDomraM7k6DRgRiWZST3KxNIx5KGjr2VPekP1v0uKn68+NhVWAkU6xNjdKHW/sB2GSiP0hha+LkVowWadCIQIByUkgntE0jPoKGXrB2L8GfS4N99Lj9blcEjma07CElZCyqYZIPwI5A10yQ1d1p0IhABCpMCmkhDeFpMQgaQ/uk0i8jiZvnj6lP0zYNpRpz2160zeRiiWGwNAxkOkwOUG0SOEA2935zUrSy2GPofRotKCelUfVULBrCkxM8fH5L42G8NGh0TyZexoHogdyWvneZfgAMkYNsMvYwd0Mln12mH+dPHsz5x8W2iqo77CJa0ohIKDfJjbrcZlAVF11uNWZ0L3m97e7biXE28FxP4vZCaqexp3EdIgfr0/pLEftN143y0N1pSSMCEbuk0Y/DAHjxkSx1kJQZ45xpSaO7efiyKSzdeoh+mcmxzkqP5faQOEw6pSaFIU47BkB/OczmQNeVMDyW4A80LlJ0p0Nag0YEAlSQUt/ltn4Sl8TY35WpDeHdS++0RM6eGB9DQPRU7i+khL2mb/0MfUKAHA6TT3b0MtfEkhtPp7iytlFad6iWCtKg0YJKk1QfLFKpsRPjImho1FAqVFvugTlosuknxQD0oQyvBMg3XRc0+mcm078blzq1kjUCEagkiTQnWNTf5BcHQUNjhlKNteWYyDfZDHCCRn/n78EuDBrhdKdjWoNGBIJQZZJIkjosAnz3BKd6IaHlmb+6gvb3V6qxthwTB8gmh8NYBOpLHAdNVrSy1uNo0IggWNIAuz1jSq79nMTYBw2lVGNtuYw6aLLxiKEvJfUlja6snmqJ6Qb3hGvQiEAEqpygkUINXr8zcGFC7KunlFLtd8D0BuyqqWDvyAJiW9KQNoW92NKG8BZUGLuxKlVq8PidMfa1pKFUtxYsVfSXYvpLMYUmkzo9FbqmJY0IBAmpnqrB43Nu8ouDNg2lVGNtbQgHGCBF9JNiCuKgPeOMMfad6mfHyex8LdHwGkmT6imPL2Cnx0HvKaVU+xXSC78R+jkljXhozzi6fwY7fnd2rLPhipY0IhDs+zTArp6ytKShVI8QwKKALAZQTK4UxUXQ6E60pNGCKpw2Darx+JzyrwYNpbq9Ayab4dZ+cqSkfjwq5Y6WNCIQaWjTSKEGy1dpBwxLvzKlursDpg/TnMmYdmjQaBM9A0YgNOk95avSUoZSPcQGZ1h0gJ1GJ19qi5gEDRH5g4hsEJHVIvKiiGSFvHaTiGwRkY0iMjckfYqIrHFeu0+ifFt06H0aqVQjvkrtbqtUD/FlYET9cy1ptI2roCEig0TkRBE5Jfjo4HrfAcYbYyYCm4CbnPWMBRYC44B5wIMi4twgwUPAtcAo5zGvg3lokT3KrV3SSKMGq7YcEmM/1atSquOCQeMN/zQqSIlxbrqXVhvCReT3wDeB9YDfSTbAR+1dqTHm7ZB/PwUudJ4vABYbY2qA7SKyBZguIjuATGPMUidPTwHnAW+0Nw9uBLCoMElkSCVWbVlczA+ulOq4IjKZUX1/lw6J3lO46T11HjDaOZFHw9XAs87zQdhBJGiPk1bnPG+aHjXB2q8yUsmgEqkphV5a96lUT3EAna2vPdwEjW1AAtCmoCEi7wLhzrK3GGNedpa5BfABfwu+LczypoX0SOu+FrsqiyFDhrQh1yGf4fwtNymkS5VdPaUlDaXUEc5N0KgEVonIe4QEDmPMD1p6kzFmdkuvi8gVwDnAGcbUz1u1BxgcslgesM9JzwuTHmndi4BFAFOnTm3fsJFO1CgjlcxgSSMOpnpVSqlYchM0XnEenUZE5gH/A5xqjKlssq5nROQeYCB2g/fnxhi/iJSJyAzgM+By4P7OzFMkZfUljTJI1qChVDzqTqPEdnctBg2n59IcY8xlnbzePwFJwDtO28GnxpjvGWPWichz2I3uPuB6Y0yw8f064EkgBbsBPKqN4MGdUJIzGSpFSG2NVk8ppY54LQYN5wo/R0QSjTG1LS3bFsaYkS28didwZ5j05cD4zspDa4J3gXhTe9GnvMD+J6lXV61eKaXikpvqqR3AJyLyClARTDTG3BOtTMWDYGG32koDvxMvtaShlDrCuQka+5yHBRwxZ81gSaPaEzIUurZpKKWOcK0GDWPMr7oiI/Gq0goJFMmxn6xFKdXc7LH9OGv8AN5YeyDWWenx3NwR/gFh7okwxpwelRzFiWBDeEFSSA/gvqNilBulVEuSvB7u/eaxvLH2zVhnpcdzUz31s5DnycAF2D2berRg9dTBpGENiWk5MclL0Hs/PZXKGn/rCyqlVJS4qZ5a0STpExH5MEr5iRvBoHHYm9M8MUZG5KTHdP1KxTMrxsfnkcJN9VTvkH8tYArhhwfpmSyBk38GvYfHOidKqRZYGjO6hJvqqRU0jP/kA7YD10QzU/HBubkPgTN+GeO8KKVaoyWNruEmaIwxxlSHJohIUpTyEzeC+5/uh0p1Dx09VnUoEnfcBI0lwOQmaUvDpPUouvso1b20dzLPK08cRo3Pz8/OHN3JOeqZIgYNERmAPWdFiogcR8N5NBPo8fOe1pc0YpsNpVQH9E1PpLC85RGQbv/auC7KTc/QUkljLnAl9jDkoUOGlAI3RzFPcUWrp5Tqnr687UxSEz2MuiXy2KaDsnSq17aKGDSMMX8B/iIiFxhjXujCPMUFCW0IV0p1O71SEgB44qppXPXEsrDLfHJjj75HOSosF8t8IiKPicgbACIyVkR6fO8pbQhXqmc4bXQ/bp5/TKyz0WO4aQh/wnnc4vy/CXtO78eilal4oLFCqe5n1a1zWL6jmJRET6P075x8FMbAb9/YEKOc9RxuShp9jTHPAQEAY4wPOGLGstCShlLdR1ZqIrPH9uekkX0bpYsI2WmJjdKOyklDtZ2boFEhIn1wBi10plwtiWqu4kBD9z2NGkr1BE2P5Pd/OisW2ej23FRP/QR77u4RIvIJkANcGNVcxREtaSjVM+gd452jtTnCLeyRbU8FRmMH643GmLouyFtM6f6lVM+ix3TnaG2O8ICI3G2MOQFY10V5igsNXW6VUj2BBo3O4aZN420RuUDae49+N3dkbrVSPY/ec9U53LZppAE+EanGvvg2xpgePWF2wzAiuqMppVSQm0mYMroiI/Gmvu+UxgyllKrnpnrqiKTBQimlmtOg0QqNHUop1SAmQUNE7hCR1SKySkTeFpGBIa/dJCJbRGSjiMwNSZ8iImuc1+6LdsN88OOP0PZ/pZQKy1XQEJGZInKV8zxHRDo6YfYfjDETjTHHAq8CtzqfPRZYCIwD5gEPikhwEJmHgGuBUc5jXgfz0CINFUop1VyrQUNEbgP+B7jJSUoAnu7ISo0xpSH/puEMUQIsABYbY2qMMduBLcB0EckFMo0xS40xBngKOK8jeWiVRg2llGrGTZfb84HjgJUAxph9ItLhHlUicidwOfY4Vqc5yYOAT0MW2+Ok1TnPm6ZH+uxrsUslDBkypH35C97cp8FDKaXquameqnWu7oMDFroaGlJE3hWRtWEeCwCMMbcYYwYDfwP+K/i2MB9lWkgPyxizyBgz1RgzNScnx012I2+HFjmUUqqem5LGcyLyZyBLRL4DXA080tqbjDGzXebhGeA14DbsEsTgkNfygH1Oel6Y9KjRSZiUUqq5Vksaxpj/BZ4HXsAetPBWY8z9HVmpiIwK+fdrQHBmlFeAhSKS5DS2jwI+N8bsB8pEZIbTa+py4OWO5KHVPDb5q5RSyl1JA2PMO8A7nbje34nIaOyJnXYC33PWs05EngPWAz7gemNMcMKn64AngRTgDecRNVrCUEqp5iIGDREpo+V2g3aPPWWMuaCF1+4E7gyTvhwY3951tpcGD6WUahAxaATHnBKRXwMHgL9i19ZcCvT48agaek9p1FBKqSA3vafmGmMeNMaUGWNKjTEPARFLCj1Fwyi3SimlgtwEDb+IXCoiHhGxRORSwN/qu7o5DRZKKdWcm6BxCXARkA8cBL7hpB0ZNHoopVQ9N/Np7MAe3uPIEhywUKOGUkrVczP2VJ6IvCgiB0UkX0ReEJG81t7X3ekkTEop1Zyb6qknsG+6G4g93tO/nLQeLRgsTMROx0opdeRxEzRyjDFPGGN8zuNJoGMDOnUDWi2llFLNuQkahSJymdN7yiMilwGHop2xeKHVU0op1cBN0Lgau/fUAedxoZPWo2mwUEqp5tz0ntqFPajgESUYM7RNQymlGrjpPXWXiGSKSIKIvCcihU4VVY+mJQ2llGrOTfXUmc70rOdgz2txNPDzqOYqjmjwUEqpBm6CRoLzdz7wd2NMURTzEzd0oEKllGrOzXwa/xKRDUAV8H0RyQGqo5stpZRS8cjNzH03AicAU40xdUAFR9CwItoQrpRSDVqahOl0Y8z7IvL1kLTQRf4ZzYwppZSKPy1VT50KvA+cG+Y1wxESNLRpQymlGrQ0c99tzt+rui47Siml4pmb+zT6iMh9IrJSRFaIyP+JSJ+uyFw80DYNpZRq4KbL7WKgAHuK1wud589GM1NKKaXik5sut72NMXeE/P8bETkvWhmKN9qmoZRSDdyUND4QkYXO/OCWiFwEvBbtjCmllIo/boLGd4FngFqgBru66iciUiYipdHMnFJKqfji5ua+DGOMZYzxGmMSnOcZziOzIysXkZ+JiBGRviFpN4nIFhHZKCJzQ9KniMga57X7pIvG+dCGcKV6Bo+ldc2dwU3vKXEmYfql8/9gEZne0RWLyGBgDrArJG0ssBAYB8wDHhQRj/PyQ8C1wCjnMa+jeVBKHTnmjR/AhVPyYp2Nbs9N9dSD2MOIXOL8Xw480Anrvhe4AftGwaAFwGJjTI0xZjuwBZguIrlApjFmqTHGAE8BXdIYrw3hSvUMCR6Lm+ePiXU2uj03QeN4Y8z1OIMUGmOKgcSOrFREvgbsNcZ82eSlQcDukP/3OGmDnOdN0yN9/rUislxElhcUFHQkq0qpHkSvATvOTZfbOqeKyAA4o9wGWnuTiLwLDAjz0i3AzcCZ4d4WJs20kB6WMWYRsAhg6tSpHWqV0DYNpXoOrTnoODdB4z7gRaCfiNyJfYPfL1p7kzFmdrh0EZkADAe+dNqy84CVTjvJHmBwyOJ5wD4nPS9MulJKuSZa1ugwN3OE/01EVgBnYF/xn2eM+aq9KzTGrAH6Bf8XkR3Yw64XisgrwDMicg8wELvB+3NjjN/p4jsD+Ay4HLi/vXloC70yUaoH0eO5w9yUNDDGbAA2RDkvGGPWichzwHrAB1xvjPE7L18HPAmkAG84D6WUck0vAjvOVdCIJmPMsCb/3wncGWa55cD4LsqWUkqpMNz0njqiaUO4Uj2HFjQ6ToOGUuqI0UUDSfRoGjRaofuYUj2HHs4dp0FDKXXE0IvAjtOg0Qpt01Cq59D7NDpOg4ZS6oihJY2O06DRCt3JlFKqgQYNpdQRQy8CO06DhlLqiKFtGh2nQaMV2hCuVM+hJY2O06ChlDpiaMzoOA0ardArE6V6Dr0jvOM0aCiljhgaMjpOg4ZS6oihBY2O06ChlDpiaPVUx2nQUEop5ZoGDaWUUq5p0FBKKeWaBo1W6M19SinVQIOGUuqIMyAzOdZZ6La8sc5AvNPOFkr1LE9eNY0xuZmxzka3pUFDKXVEmTW6X6yz0K1p9ZRSSinXNGgopZRyLSZBQ0RuF5G9IrLKecwPee0mEdkiIhtFZG5I+hQRWeO8dp/orZ1KKdXlYlnSuNcYc6zzeB1ARMYCC4FxwDzgQRHxOMs/BFwLjHIe82KQZ6WUOqLFW/XUAmCxMabGGLMd2AJMF5FcINMYs9QYY4CngPNimVGllDoSxTJo/JeIrBaRx0Uk20kbBOwOWWaPkzbIed40PSwRuVZElovI8oKCgg5lUm/uU0qpBlELGiLyroisDfNYgF3VNAI4FtgP3B18W5iPMi2kh2WMWWSMmWqMmZqTk9PBLVFKKRUUtfs0jDGz3SwnIo8Arzr/7gEGh7ycB+xz0vPCpEedNrcrpVSDWPWeyg3593xgrfP8FWChiCSJyHDsBu/PjTH7gTIRmeH0mroceLlLM62UUipmd4TfJSLHYlcx7QC+C2CMWScizwHrAR9wvTHG77znOuBJIAV4w3kopZTqQjEJGsaYb7Xw2p3AnWHSlwPjo5kvpZRSLYu3LrdKKaXimAYNpZRSrmnQUEop5ZoGDaWUUq5p0FBKKeWaBg2llFKuadBQSinlmgYNpZRSrmnQUEop5ZoGDaWUUq5p0FBKKeWaBg2llFKuadBQSinlmgYNpZRSrmnQUEop5ZoGDaWUUq5p0FBKKeWaBg2llFKuadBQSinlmgYNpZRSrmnQUEop5ZoGDaWUUq5p0FBKKeWaBg2llFKuxSxoiMh/i8hGEVknIneFpN8kIluc1+aGpE8RkTXOa/eJiMQm50opdeTyxmKlInIasACYaIypEZF+TvpYYCEwDhgIvCsiRxtj/MBDwLXAp8DrwDzgjWjlMdFjx9MES2OTUkoFxSRoANcBvzPG1AAYYw466QuAxU76dhHZAkwXkR1ApjFmKYCIPAWcRxSDxrdOGEpheQ3fmzUiWqtQSqluJ1bVU0cDJ4vIZyLyoYhMc9IHAbtDltvjpA1ynjdND0tErhWR5SKyvKCgoF0ZTE7wcNP8MaQmxiquKqVU/InaGVFE3gUGhHnpFme92cAMYBrwnIgcBYSrCzItpIdljFkELAKYOnVqxOWUUkq1TdSChjFmdqTXROQ64J/GGAN8LiIBoC92CWJwyKJ5wD4nPS9MulJKqS4Uq+qpl4DTAUTkaCARKAReARaKSJKIDAdGAZ8bY/YDZSIyw+k1dTnwcmyyrpRSR65YVdg/DjwuImuBWuAKp9SxTkSeA9YDPuB6p+cU2I3nTwIp2A3gUWsEV0opFZ7Y5+qea+rUqWb58uWxzoZSSnUrIrLCGDO1abreEa6UUso1DRpKKaVc06ChlFLKtR7fpiEiBcDOdr69L3avriOFbm/PdSRtK+j2doahxpicpok9Pmh0hIgsD9cQ1FPp9vZcR9K2gm5vNGn1lFJKKdc0aCillHJNg0bLFsU6A11Mt7fnOpK2FXR7o0bbNJRSSrmmJQ2llFKuadBQSinlmgaNMERknjNH+RYRuTHW+ekMIvK4iBx0BokMpvUWkXdEZLPzNzvktbBztXcXIjJYRD4Qka+ceeh/6KT3uG0WkWQR+VxEvnS29VdOeo/b1lAi4hGRL0TkVef/Hru9IrJDRNaIyCoRWe6kxWZ7jTH6CHkAHmArcBT2kO1fAmNjna9O2K5TgMnA2pC0u4Abnec3Ar93no91tjsJGO58H55Yb0MbtzcXmOw8zwA2OdvV47YZe5KydOd5AvAZ9gRnPW5bm2z3T4BngFed/3vs9gI7gL5N0mKyvVrSaG46sMUYs80YUwssxp67vFszxnwEFDVJXgD8xXn+F+x514Ppi40xNcaY7cAW7O+l2zDG7DfGrHSelwFfYU8R3OO22djKnX8TnIehB25rkIjkAWcDj4Yk99jtjSAm26tBo7lI85T3RP2NPcEVzt9+TnqP+g5EZBhwHPYVeI/cZqeqZhVwEHjHGNNjt9XxR+AGIBCS1pO31wBvi8gKEbnWSYvJ9sZqEqZ41qb5yHuoHvMdiEg68ALwI2NMqT3xY/hFw6R1m2029mRlx4pIFvCiiIxvYfFuva0icg5w0BizQkRmuXlLmLRus72Ok4wx+0SkH/COiGxoYdmobq+WNJqLNE95T5QvIrkAzt+DTnqP+A5EJAE7YPzNGPNPJ7lHb7Mx5jDwb2AePXdbTwK+JiI7sKuPTxeRp+m524sxZp/z9yDwInZ1U0y2V4NGc8uAUSIyXEQSgYXYc5f3RK8AVzjPr6Bh3vWwc7XHIH/t5swl/xjwlTHmnpCXetw2i0iOU8JARFKA2cAGeuC2AhhjbjLG5BljhmEfn+8bYy6jh26viKSJSEbwOXAmsJZYbW+sewXE4wOYj93bZitwS6zz00nb9HdgP1CHfSVyDdAHeA/Y7PztHbL8Lc72bwTOinX+27G9M7GL5KuBVc5jfk/cZmAi8IWzrWuBW530HretYbZ9Fg29p3rk9mL35PzSeawLnpNitb06jIhSSinXtHpKKaWUaxo0lFJKuaZBQymllGsaNJRSSrmmQUMppZRrGjSU6mQi8msRmd0Jn1Pe+lJKdS3tcqtUnBKRcmNMeqzzoVQoLWko5YKIXObMWbFKRP7sDBBYLiJ3i8hKEXlPRHKcZZ8UkQud578TkfUislpE/tdJG+osv9r5O8RJHy4iS0VkmYjc0WT9P3fSV4fMl5EmIq8582isFZFvdu23oo5EGjSUaoWIjAG+iT1o3LGAH7gUSANWGmMmAx8CtzV5X2/gfGCcMWYi8BvnpT8BTzlpfwPuc9L/D3jIGDMNOBDyOWdiDwUxHTgWmCIip2CPL7XPGDPJGDMeeLPTN16pJjRoKNW6M4ApwDJn+PEzsId2CADPOss8jT10SahSoBp4VES+DlQ66SdgTx4E8NeQ952EPdxLMD3oTOfxBbASOAY7iKwBZovI70XkZGNMSQe3U6lWadBQqnUC/MUYc6zzGG2MGAy5ewAAASBJREFUuT3Mco0aCI0xPuzSwQvYE+REKgmYCM9D1//bkPWPNMY8ZozZhB3M1gC/FZFb27ZZSrWdBg2lWvcecKEzl0Fwbuah2MfPhc4ylwD/CX2TM5dHL2PM68CPsKuWAJZgj84KdjVX8H2fNEkPegu42vk8RGSQiPQTkYFApTHmaeB/safzVSqqdBImpVphjFkvIr/AnjnNwh4p+HqgAhgnIiuAEux2j1AZwMsikoxdWvixk/4D4HER+TlQAFzlpP8QeEZEfohdOgmu/22nXWWpM4lUOXAZMBL4g4gEnDxd17lbrlRz2uVWqXbSLrHqSKTVU0oppVzTkoZSSinXtKShlFLKNQ0aSimlXNOgoZRSyjUNGkoppVzToKGUUsq1/w8CDJSNGyMjtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the scores\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(env.scores)), env.scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n",
    "# Plotting \n",
    "Y = np.asarray(env.log.get_log('scores'))\n",
    "Y2 = smooth(Y)\n",
    "x = np.linspace(0, len(Y), len(Y))\n",
    "fig1 = plt.figure()\n",
    "ax1 = plt.axes()\n",
    "ax1.plot(x, Y, Y2)\n",
    "plt.xlabel('episodes')\n",
    "plt.ylabel('episode return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "# model = DQN.load(\"dqn_\")\n",
    "model = PPO2.load(\"ppo2_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 509\tAverage Score: -25.51obj_center :  281.97903465113876 138.52970447450616 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 87.65814237394507  | tr : 70.45217185463092  | dl : 44.205524 | dr : 30.822073\n",
      "obj_center :  283.3602061066716 137.70299787337422 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 87.08518512522937  | tr : 71.31110912389505  | dl : 44.205524 | dr : 38.208652\n",
      "obj_center :  288.634956739965 154.33843363702124 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 85.49911957730403  | tr : 70.73815187517935  | dl : 51.82722 | dr : 38.208652\n",
      "obj_center :  290.1574954175426 154.72139429037952 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 84.9718631243249  | tr : 70.16519462646367  | dl : 52.311134 | dr : 38.208652\n",
      "obj_center :  291.68180200798014 155.09202701864524 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 84.44916240752217  | tr : 69.59223737774798  | dl : 52.793217 | dr : 38.208652\n",
      "obj_center :  293.20787022151194 155.45027085542188 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 83.9308876533016  | tr : 69.01928012903228  | dl : 53.273468 | dr : 38.208652\n",
      "obj_center :  294.73568855022967 155.79607187737224 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 83.41691591825814  | tr : 68.4463228803166  | dl : 53.75189 | dr : 38.208652\n",
      "obj_center :  296.2652057781886 156.1293842637309 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 82.90713791936507  | tr : 67.8733656316009  | dl : 54.22848 | dr : 38.208652\n",
      "obj_center :  297.8216587605049 155.158945414193 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 82.33418067064937  | tr : 68.15919538798761  | dl : 54.22848 | dr : 44.50592\n",
      "obj_center :  303.7491545392861 169.8939014654087 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 81.11070254500333  | tr : 67.58623813927191  | dl : 61.054073 | dr : 44.50592\n",
      "obj_center :  305.4158131004989 170.14448320672216 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 80.61198262237652  | tr : 67.01328089055622  | dl : 61.524403 | dr : 44.50592\n",
      "obj_center :  307.08378566238525 170.38083551973557 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 80.11667096414553  | tr : 66.44032364184054  | dl : 61.992954 | dr : 44.50592\n",
      "obj_center :  308.75301346892957 170.6028805147696 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 79.62467877785117  | tr : 65.86736639312484  | dl : 62.45972 | dr : 44.50592\n",
      "obj_center :  310.4535733138754 169.50683495694534 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 79.05172152913548  | tr : 65.87835616749939  | dl : 62.45972 | dr : 50.18195\n",
      "obj_center :  316.8033882486742 182.97053703224947 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 78.0114905487317  | tr : 65.30539891878371  | dl : 68.79668 | dr : 50.18195\n",
      "obj_center :  318.6272199196719 181.79337338156984 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 77.43853330001602  | tr : 65.14802453011744  | dl : 68.79668 | dr : 55.359493\n",
      "obj_center :  325.0072290311664 194.24613909226537 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 76.51119168621422  | tr : 64.57506728140176  | dl : 74.71863 | dr : 55.359493\n",
      "obj_center :  326.9136215537151 194.2963609537219 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 76.0289598402438  | tr : 64.00211003268606  | dl : 75.17584 | dr : 55.359493\n",
      "obj_center :  328.8199444831281 194.3294800421745 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 75.54926882464464  | tr : 63.42915278397037  | dl : 75.63123 | dr : 55.359493\n",
      "obj_center :  330.72604975347986 194.34554089848461 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 75.0720776582817  | tr : 62.856195535254685  | dl : 76.08481 | dr : 55.359493\n",
      "obj_center :  332.63184180361975 194.34444716961593 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 74.59732486945245  | tr : 62.283238286538996  | dl : 76.53654 | dr : 55.359493\n",
      "obj_center :  334.5371543102601 194.32624402164947 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 74.12497630721106  | tr : 61.71028103782331  | dl : 76.98642 | dr : 55.359493\n",
      "obj_center :  336.4418777982587 194.2908942994609 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 73.65497733004413  | tr : 61.13732378910761  | dl : 77.43444 | dr : 55.359493\n",
      "obj_center :  338.3458947351096 194.23835551261163 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 73.18728012662751  | tr : 60.56436654039192  | dl : 77.880585 | dr : 55.359493\n",
      "obj_center :  340.2490749139463 194.16861109570164 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 72.72183688563699  | tr : 59.991409291676234  | dl : 78.32484 | dr : 55.359493\n",
      "obj_center :  342.15127977712655 194.0817093238752 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 72.25861345612672  | tr : 59.418452042960546  | dl : 78.7672 | dr : 55.359493\n",
      "obj_center :  344.05234486644076 193.97759285988286 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 71.79756885696169  | tr : 58.84549479424486  | dl : 79.20764 | dr : 55.359493\n",
      "obj_center :  345.98488603872283 192.52739257579378 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 71.22461160824601  | tr : 58.62736587291133  | dl : 79.20764 | dr : 60.648945\n",
      "obj_center :  353.94273512645213 204.46527270988327 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 70.35667897984497  | tr : 58.05440862419564  | dl : 85.22643 | dr : 60.648945\n",
      "obj_center :  355.97965248863204 202.91564940095896 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 69.78372173112929  | tr : 57.74995294194232  | dl : 85.22643 | dr : 65.63781\n",
      "obj_center :  358.00097281018736 201.34572409710586 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 69.2107644824136  | tr : 56.940606261147074  | dl : 85.22643 | dr : 65.14257\n",
      "obj_center :  360.0064994519789 199.75568601497685 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 68.63780723369791  | tr : 56.12420741003379  | dl : 85.22643 | dr : 64.648994\n",
      "obj_center :  368.51556305737176 211.21979501680698 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 67.80748162686697  | tr : 55.5512501613181  | dl : 91.18972 | dr : 64.648994\n",
      "obj_center :  370.6193003784392 209.52411547304564 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 67.23452437815128  | tr : 55.21288942002484  | dl : 91.18972 | dr : 69.619484\n",
      "obj_center :  379.1868854888844 220.31737810773848 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 66.45312341634514  | tr : 54.63993217130915  | dl : 96.92294 | dr : 69.619484\n",
      "obj_center :  381.354544245587 219.8501526014195 | goal :  {'x': 388, 'y': 228, 'w': 25}\n",
      "tl : 65.99905927051186  | tr : 54.06697492259346  | dl : 97.34316 | dr : 69.619484\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tried to step environment that needs reset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-388b271bf944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/bench/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tried to step environment that needs reset"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, num_steps=1000):\n",
    "  \"\"\"\n",
    "  Evaluate a RL agent\n",
    "  :param model: (BaseRLModel object) the RL Agent\n",
    "  :param num_steps: (int) number of timesteps to evaluate it\n",
    "  :return: (float) Mean reward for the last 100 episodes\n",
    "  \"\"\"\n",
    "  episode_rewards = [0.0]\n",
    "  obs = env_test.reset()\n",
    "  for i in range(num_steps):\n",
    "      # _states are only useful when using LSTM policies\n",
    "      action, _states = model.predict(obs)\n",
    "\n",
    "      obs, reward, done, info = env_test.step(action)\n",
    "      \n",
    "      # Stats\n",
    "      episode_rewards[-1] += reward\n",
    "      if done:\n",
    "          obs = env_test.reset()\n",
    "          episode_rewards.append(0.0)\n",
    "  # Compute mean reward for the last 100 episodes\n",
    "  mean_100ep_reward = round(np.mean(episode_rewards[-100:]), 1)\n",
    "  print(\"Mean reward:\", mean_100ep_reward, \"Num episodes:\", len(episode_rewards))\n",
    "  \n",
    "  return mean_100ep_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env_test.reset()\n",
    "for i in range(10):\n",
    "  # _states are only useful when using LSTM policies\n",
    "  action, _states = model.predict(obs)\n",
    "\n",
    "  obs, reward, done, info = env_test.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3fd6c8982b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Random Agent, before training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean_reward_before_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Agent, before training\n",
    "mean_reward_before_train = evaluate(model, num_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"dqn_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadMonitorResultsError",
     "evalue": "no monitor files of the form *monitor.csv found in /tmp/gym/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLoadMonitorResultsError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aa2a24335c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Helper from the library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults_plotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_plotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_TIMESTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Friction Finger Env\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/results_plotter.py\u001b[0m in \u001b[0;36mplot_results\u001b[0;34m(dirs, num_timesteps, xaxis, task_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mtslist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_timesteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mnum_timesteps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/stable_baselines/bench/monitor.py\u001b[0m in \u001b[0;36mload_results\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mmonitor_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*monitor.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mget_monitor_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmonitor_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLoadMonitorResultsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no monitor files of the form *%s found in %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mdata_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLoadMonitorResultsError\u001b[0m: no monitor files of the form *monitor.csv found in /tmp/gym/"
     ]
    }
   ],
   "source": [
    "from stable_baselines import results_plotter\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results([log_dir], 1e5, results_plotter.X_TIMESTEPS, \"Friction Finger Env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(env.step(np.random.randint(0,5,1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
